{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ],
      "metadata": {
        "id": "VcIlq491gVbE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWBGhLW5gRB7"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr"
      ],
      "metadata": {
        "id": "nxL8nPitgqLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gr.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbEWd1u1g_rI",
        "outputId": "ffbc2ab8-13c9-4c17-b46a-a9cf7582603b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.44.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Components\n",
        "#### Input Modules\n",
        "#### Output Modules"
      ],
      "metadata": {
        "id": "jccWRq3qhPK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define input text box\n",
        "input_module = gr.Textbox(label='Original Text')\n",
        "\n",
        "out_module = gr.Textbox(label='New Text')"
      ],
      "metadata": {
        "id": "6veAjHTQhFNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define a function to communicate inputs and processing workflow to get output**"
      ],
      "metadata": {
        "id": "KiKHNz65ie3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greet(name):\n",
        "      return \"Hello \" + name + \"!\""
      ],
      "metadata": {
        "id": "9hi0JZpiiZo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=greet, inputs=input_module, outputs=out_module).launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "BSicJL3NiwPM",
        "outputId": "d4ef526e-d333-4faa-a397-b6b439f78280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://f0c9bc4b6aee6435b1.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f0c9bc4b6aee6435b1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def ml_predict(feature1, feature2, feature3, feature4, feature5):\n",
        "  feature_vector = [feature1, feature2, feature3, feature4, feature5]\n",
        "\n",
        "  # load ML model\n",
        "  model = load(...)\n",
        "\n",
        "  # make prediction\n",
        "  output = model.predict(feature_vector)\n",
        "\n",
        "  # return output\n",
        "  return output"
      ],
      "metadata": {
        "id": "tAC_AFT7jBs-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ],
      "metadata": {
        "id": "g8fIOR-cMJo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples = [[\"June 1st\"], [\"Week 2\"], [\"Matt\"], [\"Teresa\"]]"
      ],
      "metadata": {
        "id": "cSXUQtcwk7PF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=greet, inputs=input_module, outputs=out_module, examples = examples).launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "Hx1EL1f0M5-m",
        "outputId": "804c394b-5f6b-4d75-ea8c-919a19f9e526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://21791071ecd619b959.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://21791071ecd619b959.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3"
      ],
      "metadata": {
        "id": "4DtYonu9NWat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def caption(image):\n",
        "    return \"What a nice picture!\""
      ],
      "metadata": {
        "id": "fgpxDeCfM-Za"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_module = gr.Image(label = \"Input Image\")\n",
        "output_module = gr.Textbox(label = \"Output Text\")"
      ],
      "metadata": {
        "id": "oThfIh9UNanX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=caption, inputs=input_module, outputs=output_module).launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "-XVB7ATeNjSr",
        "outputId": "f37cf2dd-a5ff-4262-d812-08375f944c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://261b60b9ad6465ba33.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://261b60b9ad6465ba33.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4"
      ],
      "metadata": {
        "id": "qM1sQdFJO5bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_module1 = gr.Textbox(label = \"Input Text\")\n",
        "\n",
        "input_module2 = gr.Image(label = \"Input Image\")\n",
        "\n",
        "input_module3 = gr.Number(label = \"Input Number\")\n",
        "\n",
        "input_module4 = gr.Slider(1, 100, step=5, label = \"Input Slider\")\n",
        "\n",
        "input_module5 = gr.Checkbox(label = \"Does it work?\")\n",
        "\n",
        "input_module6 = gr.Radio(choices=[\"park\", \"zoo\", \"road\"], label = \"Input Radio\")\n",
        "\n",
        "input_module7 = gr.Dropdown(choices=[\"park\", \"zoo\", \"road\"], label = \"Input Dropdown\")"
      ],
      "metadata": {
        "id": "UyXemGsVNwNP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_module1 = gr.Textbox(label = \"Output Text\")\n",
        "\n",
        "output_module2 = gr.Image(label = \"Output Image\")"
      ],
      "metadata": {
        "id": "x3n0GXRuPXxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_inputs(input1, input2, input3, input4, input5, input6, input7 ):\n",
        "    import numpy as np\n",
        "    ## processing inputs\n",
        "\n",
        "    ## return outputs\n",
        "    output1 = \"Processing inputs and return outputs\" # text output example\n",
        "    output2 = np.random.rand(6,6) # image-like array output example\n",
        "    return output1,output2"
      ],
      "metadata": {
        "id": "vaczG6tSPblY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=multi_inputs,\n",
        "             inputs=[input_module1, input_module2, input_module3,\n",
        "                     input_module4, input_module5, input_module6,\n",
        "                     input_module7],\n",
        "             outputs=[output_module1, output_module2]\n",
        "            ).launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "DoRQCwPPPl3N",
        "outputId": "4fb1e5c9-63fe-4feb-ad41-ae0ba1e2a2a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://f31d596c8fe93d8158.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://f31d596c8fe93d8158.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## adding another textbox as input\n",
        "input_module1 = gr.Textbox(label = \"Input Text\")\n",
        "\n",
        "input_module2 = gr.Image(label = \"Input Image\")\n",
        "\n",
        "input_module3 = gr.Number(label = \"Input Number\")\n",
        "\n",
        "input_module4 = gr.Slider(1, 100, step=5, label = \"Input Slider\")\n",
        "\n",
        "input_module5 = gr.Checkbox(label = \"Does it work?\")\n",
        "\n",
        "input_module6 = gr.Radio(choices=[\"park\", \"zoo\", \"road\"], label = \"Input Radio\")\n",
        "\n",
        "input_module7 = gr.Dropdown(choices=[\"park\", \"zoo\", \"road\"], label = \"Input Dropdown\")\n",
        "\n",
        "input_module8 = gr.Textbox(label = \"Additional Textbox\")"
      ],
      "metadata": {
        "id": "aWy35zaHQktq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add another textbox as output\n",
        "output_module1 = gr.Textbox(label = \"Output Text\")\n",
        "\n",
        "output_module2 = gr.Image(label = \"Output Image\")\n",
        "\n",
        "output_module3 = gr.Textbox(label = \"Additional Output Text\")"
      ],
      "metadata": {
        "id": "7mEJ-32FQoPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_inputs(input1, input2, input3, input4, input5, input6, input7, input8):\n",
        "    import numpy as np\n",
        "    ## processing inputs\n",
        "\n",
        "    ## return outputs\n",
        "    output1 = \"Processing inputs and return outputs\" # text output example\n",
        "    output2 = np.random.rand(6,6) # image-like array output example\n",
        "    output3 = \"Outputs returned above this textbox\"\n",
        "    return output1,output2,output3"
      ],
      "metadata": {
        "id": "QpgAG7VoQ4kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=multi_inputs,\n",
        "             inputs=[input_module1, input_module2, input_module3,\n",
        "                     input_module4, input_module5, input_module6,\n",
        "                     input_module7, input_module8],\n",
        "             outputs=[output_module1, output_module2, output_module3]\n",
        "            ).launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "1Z_6i1EzRDnD",
        "outputId": "9788f700-d2e2-48ce-e1fc-9d75a8b4f268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://17a7096382f48346bd.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://17a7096382f48346bd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5"
      ],
      "metadata": {
        "id": "Stg_urpBS6fP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHCSSNliecP6",
        "outputId": "97a85930-d6fc-4009-fd50-1c6716d809c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the inputs\n",
        "import gradio as gr\n",
        "\n",
        "input_module1 = gr.Slider(-120, -10, step = 0.25, label = \"Longitude\")\n",
        "\n",
        "input_module2 = gr.Slider(30, 45, step = 0.5, label = \"Latitude\")\n",
        "\n",
        "input_module3 = gr.Slider(0, 55, step = 1, label = \"Housing Median Age\")\n",
        "\n",
        "input_module4 = gr.Slider(1, 40000, step = 1, label = \"Total Rooms\")\n",
        "\n",
        "input_module5 = gr.Slider(1, 6500, step = 1, label = \"Total Bedrooms\")\n",
        "\n",
        "input_module6 = gr.Slider(1, 36000, step = 1, label = \"Population\")\n",
        "\n",
        "input_module7 = gr.Slider(1, 6500, step = 1, label = \"Households\")\n",
        "\n",
        "input_module8 = gr.Slider(0, 15, step = 0.25, label = \"Median Income\")"
      ],
      "metadata": {
        "id": "ZFDAiYtISMjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the outputs\n",
        "output = gr.Number(label = \"Predicted Housing Price\")"
      ],
      "metadata": {
        "id": "AFt_PmfCMwZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define function that accepts the collected features and returns the predicted\n",
        "# housing price\n",
        "def predict(input1, input2, input3, input4, input5, input6, input7, input8):\n",
        "  import numpy as np\n",
        "  from joblib import load\n",
        "\n",
        "  inputs = np.array([[input1, input2, input3, input4, input5, input6, input7, input8]])\n",
        "\n",
        "  scaler = load(\"/content/scaler.joblib\")\n",
        "\n",
        "  inputs_normalized = scaler.transform(inputs)\n",
        "\n",
        "  model = load(\"/content/best_knn_model.joblib\")\n",
        "\n",
        "  output = model.predict(inputs_normalized)\n",
        "\n",
        "  return output[0]"
      ],
      "metadata": {
        "id": "zsgJdd-kMxp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=predict, inputs=[input_module1, input_module2, input_module3, input_module4, input_module5, input_module6, input_module7, input_module8],\n",
        "             outputs=output).launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "r3Qg7GPtHAxe",
        "outputId": "03c61ac1-44b8-482e-d296-e021425056b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://e6315201e931552c8b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e6315201e931552c8b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}