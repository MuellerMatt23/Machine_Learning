{"cells":[{"cell_type":"markdown","source":["# Homework 04:  Implementing Recurrent Neural Network for protein secondary structure prediction"],"metadata":{"id":"i_SJkZuwr4zg"}},{"cell_type":"markdown","metadata":{"id":"bYeBLxp2fxbp"},"source":["##PART 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4061,"status":"ok","timestamp":1743706987907,"user":{"displayName":"Matthew Mueller","userId":"09372831935304640262"},"user_tz":300},"id":"41vkCJadgzOl","outputId":"304f463e-3a2a-4120-9d37-459d2753edd1"},"outputs":[{"output_type":"stream","name":"stdout","text":["--- Configuration ---\n","Amino Acids Mapping: \n"," {'A': 0, 'R': 1, 'N': 2, 'D': 3, 'C': 4, 'Q': 5, 'E': 6, 'G': 7, 'H': 8, 'I': 9, 'L': 10, 'K': 11, 'M': 12, 'F': 13, 'P': 14, 'S': 15, 'T': 16, 'W': 17, 'Y': 18, 'V': 19}\n","Number of Amino Acid Classes: 20\n","\n","Secondary Structure Mapping: \n"," {'C': 0, 'H': 1, 'E': 2}\n","Number of Secondary Structure Classes: 3\n","------------------------------\n","\n","==================================================\n","Starting Data Preparation Pipeline\n","==================================================\n","\n","--- Step 1: Checking/Downloading Data Files ---\n","ss_train.txt already exists locally.\n","ss_test.txt already exists locally.\n","\n","--- Step 2: Loading Raw Data ---\n","Attempting to load data from: ss_train.txt\n","Skipping header line: '1180 20 3'\n","Successfully loaded 1180 sequences and 1180 structures from ss_train.txt.\n","Attempting to load data from: ss_test.txt\n","Skipping header line: '126 20 3'\n","Successfully loaded 126 sequences and 126 structures from ss_test.txt.\n","\n","--- Step 3: Determining Maximum Sequence Length ---\n","Maximum valid sequence length found (used for padding): 1231\n","\n","--- Step 4: Generating Features (One-Hot Encoding & Padding) ---\n","Processing Training Data...\n","Processing 1180 raw sequences...\n","Successfully processed 1166 sequences.\n","Skipped 14 sequences out of 1180 (due to length mismatch, 'X', or unknown chars).\n","Padding sequences to maximum length: 1231\n","Generated features shapes -> X: (1166, 1231, 20), Y: (1166, 1231, 3)\n","\n","Processing Test Data...\n","Processing 126 raw sequences...\n","Successfully processed 124 sequences.\n","Skipped 2 sequences out of 126 (due to length mismatch, 'X', or unknown chars).\n","Padding sequences to maximum length: 1231\n","Generated features shapes -> X: (124, 1231, 20), Y: (124, 1231, 3)\n","\n","--- Step 5: Splitting Data into Training and Validation Sets ---\n","Split original training data (1166 samples) into:\n","  - Training set:   932 samples\n","  - Validation set: 234 samples\n","\n","==================================================\n","Final Dataset Summary\n","==================================================\n","Total number of samples processed (Train + Validation + Test): 1290\n","  (Note: Original raw files had 1180 train and 126 test sequences before filtering)\n","\n","Dataset Shapes:\n","  Training Set (X_train):   (932, 1231, 20)\n","  Training Set (Y_train):   (932, 1231, 3)\n","  Validation Set (X_val):   (234, 1231, 20)\n","  Validation Set (Y_val):   (234, 1231, 3)\n","  Test Set (X_test):      (124, 1231, 20)\n","  Test Set (Y_test):      (124, 1231, 3)\n","\n","Feature Dimensions:\n","  Sequence Length (after padding):         1231\n","  Input Features per time step (Amino Acids): 20 (One-hot)\n","  Output Labels per time step (Structures):  3 (One-hot)\n","\n","Data preparation complete. The variables X_train, Y_train, X_val, Y_val, X_test, Y_test are ready for model training/evaluation.\n","==================================================\n","\n","Example: First sample in the processed training set\n","  X_train[0] shape: (1231, 20)\n","  Y_train[0] shape: (1231, 3)\n"]}],"source":["\"\"\"\n","Protein Secondary Structure Prediction Data Preparation\n","\"\"\"\n","\n","import numpy as np\n","import os\n","from sklearn.model_selection import train_test_split\n","# Using tensorflow's padding utility is convenient\n","# Ensure tensorflow is installed: pip install tensorflow\n","try:\n","    from tensorflow.keras.preprocessing.sequence import pad_sequences\n","except ImportError:\n","    print(\"---------------------------------------------------------\")\n","    print(\"ERROR: TensorFlow not found.\")\n","    print(\"This script uses TensorFlow/Keras for padding sequences.\")\n","    print(\"Please install it: pip install tensorflow\")\n","    print(\"Alternatively, you can modify the script to implement manual padding.\")\n","    print(\"---------------------------------------------------------\")\n","    exit() # Stop execution if TF is not available\n","\n","# -----------------------------------------------------------------------------\n","# Constants and Mappings\n","# -----------------------------------------------------------------------------\n","\n","# Define constants for amino acids and secondary structures\n","AMINO_ACIDS = 'ARNDCQEGHILKMFPSTWYV' # 20 standard amino acids\n","SECONDARY_STRUCTURES = 'CHE'        # C: Coil, H: Helix, E: Strand (Sheet)\n","UNKNOWN_AMINO_ACID = 'X'            # Character sometimes used for unknown/non-standard AAs\n","\n","# Create mapping dictionaries from character to integer index\n","amino_acid_mapping = {amino_acid: i for i, amino_acid in enumerate(AMINO_ACIDS)}\n","secondary_structure_mapping = {secondary_structure: i for i, secondary_structure in enumerate(SECONDARY_STRUCTURES)}\n","\n","NUM_AMINO_ACIDS = len(AMINO_ACIDS)\n","NUM_SECONDARY_STRUCTURES = len(SECONDARY_STRUCTURES)\n","\n","print(\"--- Configuration ---\")\n","print(\"Amino Acids Mapping: \\n\", amino_acid_mapping)\n","print(\"Number of Amino Acid Classes:\", NUM_AMINO_ACIDS)\n","print(\"\\nSecondary Structure Mapping: \\n\", secondary_structure_mapping)\n","print(\"Number of Secondary Structure Classes:\", NUM_SECONDARY_STRUCTURES)\n","print(\"-\" * 30)\n","\n","# -----------------------------------------------------------------------------\n","# Requirement 3: Define a data loader function to parse the files\n","# -----------------------------------------------------------------------------\n","def data_loader(file_path):\n","    \"\"\"\n","    Parses the protein data text file based on the observed format:\n","    - Skips the first line (metadata).\n","    - Expects blocks of: ID line, Sequence line, Structure line.\n","    - Handles blank lines between blocks.\n","    - Validates that sequence and structure lengths match for each pair.\n","\n","    Args:\n","        file_path (str): Path to the data file.\n","\n","    Returns:\n","        tuple: A tuple containing two lists:\n","               - sequences (list): List of amino acid sequence strings.\n","               - structures (list): List of corresponding secondary structure strings.\n","               Returns empty lists if the file cannot be read or is empty.\n","    \"\"\"\n","    sequences, structures = [], []\n","    current_sequence = None\n","    # State: 0=Expecting ID (or blank), 1=Expecting Sequence, 2=Expecting Structure\n","    expected_line_type = 0\n","\n","    print(f\"Attempting to load data from: {file_path}\")\n","    if not os.path.exists(file_path):\n","        print(f\"Error: File not found at {file_path}.\")\n","        return [], [] # Return empty lists if file doesn't exist\n","\n","    try:\n","        with open(file_path, 'r') as file:\n","            lines = file.readlines()\n","\n","        if not lines:\n","            print(\"Warning: File is empty.\")\n","            return [], []\n","\n","        # --- Skip the first metadata line ---\n","        if len(lines) > 0:\n","            print(f\"Skipping header line: '{lines[0].strip()}'\")\n","        line_iterator = iter(lines[1:]) # Start processing from the second line\n","\n","        for line_num, line in enumerate(line_iterator, start=2): # Line numbers relative to original file\n","            stripped_line = line.strip()\n","\n","            if not stripped_line:\n","                # Ignore blank lines, reset expectation to ID if needed.\n","                if expected_line_type != 0:\n","                    expected_line_type = 0\n","                    current_sequence = None # Reset incomplete pair\n","                continue # Skip processing this blank line\n","\n","            # --- Process non-blank lines based on expected type ---\n","            if expected_line_type == 0:\n","                # This should be the ID line. We don't store it, just advance state.\n","                expected_line_type = 1 # Now expect the sequence\n","            elif expected_line_type == 1:\n","                # This should be the sequence. Store it.\n","                current_sequence = stripped_line\n","                expected_line_type = 2 # Now expect the structure\n","            elif expected_line_type == 2:\n","                # This should be the structure. Store it and finalize the pair.\n","                current_structure = stripped_line\n","\n","                # Validate and store the completed pair\n","                if current_sequence: # Ensure we have a sequence stored\n","                    if len(current_sequence) == len(current_structure):\n","                        sequences.append(current_sequence)\n","                        structures.append(current_structure)\n","                    else:\n","                        print(f\"Warning @ line ~{line_num}: Sequence/Structure length mismatch. \"\n","                              f\"Seq len: {len(current_sequence)}, Struct len: {len(current_structure)}. Skipping pair.\")\n","                else:\n","                    print(f\"Warning @ line ~{line_num}: Found structure but no preceding sequence stored. Skipping.\")\n","\n","                # Reset for the next block\n","                current_sequence = None\n","                expected_line_type = 0 # Expect an ID (or blank line) next\n","\n","    except Exception as e:\n","        print(f\"An error occurred during file reading/parsing of {file_path}: {e}\")\n","        import traceback\n","        traceback.print_exc()\n","        return [], [] # Return empty on error\n","\n","    print(f\"Successfully loaded {len(sequences)} sequences and {len(structures)} structures from {file_path}.\")\n","    if len(sequences) == 0 and len(lines) > 1:\n","         print(\"Warning: Failed to load any valid sequence/structure pairs. Check file format/content.\")\n","    elif len(sequences) != len(structures):\n","         # This check is belt-and-suspenders if pair validation works\n","         print(f\"Error: Final count mismatch! Sequences: {len(sequences)}, Structures: {len(structures)}\")\n","\n","    return sequences, structures\n","\n","# -----------------------------------------------------------------------------\n","# Requirement 4: Define feature generation functions\n","# -----------------------------------------------------------------------------\n","def generate_features(sequences, structures, aa_map, ss_map, max_seq_length, filter_unknown=True):\n","    \"\"\"\n","    Generates one-hot encoded features for sequences (X) and labels (Y),\n","    and pads them to a maximum length. This creates data suitable for RNNs.\n","\n","    Args:\n","        sequences (list): List of amino acid sequence strings.\n","        structures (list): List of secondary structure strings.\n","        aa_map (dict): Mapping from amino acid characters to integers.\n","        ss_map (dict): Mapping from structure characters to integers.\n","        max_seq_length (int): The length to pad sequences and structures to.\n","        filter_unknown (bool): If True, sequences containing unknown amino acids ('X')\n","                               will be skipped.\n","\n","    Returns:\n","        tuple: A tuple containing two NumPy arrays:\n","               - X (np.array): Padded one-hot encoded sequences\n","                               (shape: num_samples, max_seq_length, num_aa_features).\n","               - Y (np.array): Padded one-hot encoded structures\n","                               (shape: num_samples, max_seq_length, num_ss_features).\n","               Returns empty arrays of the correct shape if no valid sequences are processed.\n","    \"\"\"\n","    num_aa_features = len(aa_map)\n","    num_ss_features = len(ss_map)\n","    X_list = [] # List to hold one-hot encoded sequences (before padding)\n","    Y_list = [] # List to hold one-hot encoded structures (before padding)\n","\n","    skipped_count = 0\n","    original_count = len(sequences)\n","    print(f\"Processing {original_count} raw sequences...\")\n","\n","    for i, seq in enumerate(sequences):\n","        # Basic check (already done in data_loader, but good for robustness here)\n","        if i >= len(structures):\n","            print(f\"Warning: Index {i} out of bounds for structures list (length {len(structures)}). Stopping feature generation.\")\n","            break\n","        struct = structures[i]\n","        if len(seq) != len(struct):\n","            # This should ideally not happen if data_loader worked correctly\n","            print(f\"Warning (Feature Gen): Sequence/structure length mismatch at index {i}. Skipping.\")\n","            skipped_count += 1\n","            continue\n","\n","        # Optional: Filter sequences containing unknown amino acids\n","        if filter_unknown and UNKNOWN_AMINO_ACID in seq:\n","            skipped_count += 1\n","            continue\n","\n","        # --- One-hot encode sequence (X) ---\n","        x_one_hot = np.zeros((len(seq), num_aa_features), dtype=np.float32)\n","        valid_seq = True\n","        for j, aa in enumerate(seq):\n","            if aa in aa_map:\n","                x_one_hot[j, aa_map[aa]] = 1.0\n","            else:\n","                # This should only happen if filter_unknown is False and 'X' (or other chars) are present\n","                print(f\"Warning: Unknown amino acid '{aa}' found in sequence {i} at pos {j}. Skipping sequence.\")\n","                valid_seq = False\n","                skipped_count +=1\n","                break\n","        if not valid_seq:\n","            continue # Skip to next sequence\n","\n","        # --- One-hot encode structure (Y) ---\n","        y_one_hot = np.zeros((len(struct), num_ss_features), dtype=np.float32)\n","        valid_struct = True\n","        for j, ss in enumerate(struct):\n","            if ss in ss_map:\n","                y_one_hot[j, ss_map[ss]] = 1.0\n","            else:\n","                 print(f\"Warning: Unknown structure char '{ss}' found in structure {i} at pos {j}. Skipping sequence.\")\n","                 valid_struct = False\n","                 skipped_count += 1 # Count as skipped if structure is bad\n","                 break\n","        if not valid_struct:\n","             # We already one-hot encoded X, but since Y is invalid, discard this pair\n","             continue # Skip to next sequence\n","\n","        # If both sequence and structure are valid, add to lists\n","        X_list.append(x_one_hot)\n","        Y_list.append(y_one_hot)\n","\n","    processed_count = len(X_list)\n","    print(f\"Successfully processed {processed_count} sequences.\")\n","    if skipped_count > 0:\n","        print(f\"Skipped {skipped_count} sequences out of {original_count} (due to length mismatch, '{UNKNOWN_AMINO_ACID}', or unknown chars).\")\n","\n","    # Handle case where NO sequences were processed\n","    if not X_list:\n","        print(\"Warning: No valid sequences left after filtering/processing.\")\n","        # Return empty arrays with the correct number of dimensions for downstream consistency\n","        return np.array([]).reshape(0, max_seq_length, num_aa_features), \\\n","               np.array([]).reshape(0, max_seq_length, num_ss_features)\n","\n","    # --- Pad sequences to max_seq_length ---\n","    # 'padding=post' adds padding (zeros) at the end of the sequence.\n","    # 'value=0.0' uses zero vectors for padding.\n","    # 'dtype=float32' is common for NN inputs.\n","    print(f\"Padding sequences to maximum length: {max_seq_length}\")\n","    X_padded = pad_sequences(X_list, maxlen=max_seq_length, padding='post', dtype='float32', value=0.0)\n","    Y_padded = pad_sequences(Y_list, maxlen=max_seq_length, padding='post', dtype='float32', value=0.0)\n","\n","    print(f\"Generated features shapes -> X: {X_padded.shape}, Y: {Y_padded.shape}\")\n","    # Expected shape: (num_samples, max_seq_length, num_features_per_step)\n","    return X_padded, Y_padded\n","\n","\n","# -----------------------------------------------------------------------------\n","# Main Script Logic: Requirements 1, 2, and Orchestration\n","# -----------------------------------------------------------------------------\n","\n","print(\"\\n\" + \"=\"*50)\n","print(\"Starting Data Preparation Pipeline\")\n","print(\"=\"*50)\n","\n","# --- Define File Paths and URLs ---\n","train_url = \"http://calla.rnet.missouri.edu/cheng_courses/mlbioinfo/ss_train.txt\"\n","test_url = \"https://calla.rnet.missouri.edu/cheng_courses/mlbioinfo/ss_test.txt\"\n","train_file_path = \"ss_train.txt\"\n","test_file_path = \"ss_test.txt\"\n","\n","# --- Requirement 1 & 2 (Part 1): Download Data ---\n","print(\"\\n--- Step 1: Checking/Downloading Data Files ---\")\n","for url, file_path in [(train_url, train_file_path), (test_url, test_file_path)]:\n","    if not os.path.exists(file_path):\n","        print(f\"Downloading {os.path.basename(file_path)} from {url}...\")\n","        try:\n","            # Using os.system - requires wget to be installed on the system\n","            # Alternatives: requests library, urllib\n","            download_command = f\"wget -O {file_path} {url}\"\n","            print(f\"Executing: {download_command}\")\n","            status = os.system(download_command)\n","            if status != 0:\n","                print(f\"Error: Download failed for {file_path} (wget returned non-zero status: {status}).\")\n","                print(\"Please check the URL and your internet connection, or download manually.\")\n","                exit() # Stop if download fails\n","            print(f\"{os.path.basename(file_path)} downloaded successfully.\")\n","        except Exception as e:\n","            print(f\"Error during download of {file_path}: {e}\")\n","            print(\"Please check if 'wget' is installed and in your PATH, or download manually.\")\n","            exit() # Stop if download fails\n","    else:\n","        print(f\"{os.path.basename(file_path)} already exists locally.\")\n","\n","# --- Requirement 1 & 3: Load Raw Data using data_loader ---\n","print(\"\\n--- Step 2: Loading Raw Data ---\")\n","raw_sequences_train, raw_structures_train = data_loader(train_file_path)\n","raw_sequences_test, raw_structures_test = data_loader(test_file_path)\n","\n","# --- Basic Validation After Loading ---\n","if not raw_sequences_train or not raw_structures_train:\n","    print(\"\\nError: Failed to load sufficient training data. Exiting.\")\n","    exit()\n","if not raw_sequences_test or not raw_structures_test:\n","    print(\"\\nWarning: Failed to load test data. Test set will be empty.\")\n","    # Allow continuing, but test set evaluation won't be possible.\n","\n","# --- Determine Maximum Sequence Length for Padding ---\n","# Important: Calculate based on VALID sequences across ALL data before processing/filtering 'X'\n","print(\"\\n--- Step 3: Determining Maximum Sequence Length ---\")\n","all_raw_sequences = raw_sequences_train + raw_sequences_test\n","valid_sequences = [seq for seq in all_raw_sequences if UNKNOWN_AMINO_ACID not in seq]\n","\n","if not valid_sequences:\n","     print(\"\\nError: No valid sequences found (without 'X') across train and test sets. Cannot determine padding length.\")\n","     exit()\n","\n","max_len = max(len(seq) for seq in valid_sequences)\n","print(f\"Maximum valid sequence length found (used for padding): {max_len}\")\n","\n","# --- Requirement 1 & 4: Generate Features (One-Hot Encode + Pad) ---\n","print(\"\\n--- Step 4: Generating Features (One-Hot Encoding & Padding) ---\")\n","print(\"Processing Training Data...\")\n","X_train_full, Y_train_full = generate_features(\n","    raw_sequences_train,\n","    raw_structures_train,\n","    amino_acid_mapping,\n","    secondary_structure_mapping,\n","    max_len,\n","    filter_unknown=True # Skip sequences with 'X'\n",")\n","\n","print(\"\\nProcessing Test Data...\")\n","X_test, Y_test = generate_features(\n","    raw_sequences_test,\n","    raw_structures_test,\n","    amino_acid_mapping,\n","    secondary_structure_mapping,\n","    max_len,\n","    filter_unknown=True # Skip sequences with 'X'\n",")\n","\n","# --- Check if Feature Generation Succeeded ---\n","if X_train_full.shape[0] == 0:\n","    print(\"\\nError: No training samples remain after feature generation. Check data and filtering.\")\n","    exit()\n","if X_test.shape[0] == 0:\n","    print(\"\\nWarning: No test samples remain after feature generation. Test set is empty.\")\n","\n","# --- Requirement 2: Prepare training/validation/test sets ---\n","print(\"\\n--- Step 5: Splitting Data into Training and Validation Sets ---\")\n","# Split the *processed* full training set into actual training and validation sets\n","# Common split ratios are 80/20 or 90/10 for train/validation\n","validation_split_size = 0.2 # Use 20% of the original training data for validation\n","\n","X_train, X_val, Y_train, Y_val = train_test_split(\n","    X_train_full, # Feature matrix from the original training file\n","    Y_train_full, # Label matrix from the original training file\n","    test_size=validation_split_size,\n","    random_state=42, # Ensures reproducible splits\n","    shuffle=True     # Shuffle data before splitting (good practice)\n",")\n","\n","print(f\"Split original training data ({X_train_full.shape[0]} samples) into:\")\n","print(f\"  - Training set:   {X_train.shape[0]} samples\")\n","print(f\"  - Validation set: {X_val.shape[0]} samples\")\n","\n","\n","# --- Requirement 2: Report total samples and feature dimensions ---\n","print(\"\\n\" + \"=\"*50)\n","print(\"Final Dataset Summary\")\n","print(\"=\"*50)\n","\n","total_processed_samples = X_train.shape[0] + X_val.shape[0] + X_test.shape[0]\n","print(f\"Total number of samples processed (Train + Validation + Test): {total_processed_samples}\")\n","print(f\"  (Note: Original raw files had {len(raw_sequences_train)} train and {len(raw_sequences_test)} test sequences before filtering)\")\n","\n","print(\"\\nDataset Shapes:\")\n","print(f\"  Training Set (X_train):   {X_train.shape}\")\n","print(f\"  Training Set (Y_train):   {Y_train.shape}\")\n","print(f\"  Validation Set (X_val):   {X_val.shape}\")\n","print(f\"  Validation Set (Y_val):   {Y_val.shape}\")\n","print(f\"  Test Set (X_test):      {X_test.shape}\")\n","print(f\"  Test Set (Y_test):      {Y_test.shape}\")\n","\n","print(\"\\nFeature Dimensions:\")\n","print(f\"  Sequence Length (after padding):         {max_len}\")\n","print(f\"  Input Features per time step (Amino Acids): {NUM_AMINO_ACIDS} (One-hot)\")\n","print(f\"  Output Labels per time step (Structures):  {NUM_SECONDARY_STRUCTURES} (One-hot)\")\n","\n","print(\"\\nData preparation complete. The variables X_train, Y_train, X_val, Y_val, X_test, Y_test are ready for model training/evaluation.\")\n","print(\"=\"*50)\n","\n","# --- Optional: Example output of the first processed sample ---\n","if X_train.shape[0] > 0:\n","    print(\"\\nExample: First sample in the processed training set\")\n","    print(\"  X_train[0] shape:\", X_train[0].shape) # Should be (max_len, num_amino_acids)\n","    # print(\"  X_train[0] (first 10 steps):\\n\", X_train[0,:10,:]) # Print first 10 time steps features\n","    print(\"  Y_train[0] shape:\", Y_train[0].shape) # Should be (max_len, num_structures)\n","    # print(\"  Y_train[0] (first 10 steps):\\n\", Y_train[0,:10,:]) # Print first 10 time steps labels"]},{"cell_type":"markdown","metadata":{"id":"7608VQnGfz9r"},"source":["##PART 2"]},{"cell_type":"markdown","metadata":{"id":"B2ep4MxTgRhq"},"source":["###TASK - 1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1353,"status":"ok","timestamp":1743706992766,"user":{"displayName":"Matthew Mueller","userId":"09372831935304640262"},"user_tz":300},"id":"CpGaN82NhD5P","outputId":"48231847-6bec-467f-fc32-1bd849635be1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using variables from Part I: max_len=1231, NUM_AMINO_ACIDS=20, NUM_SECONDARY_STRUCTURES=3\n","\n","============================================================\n","Building Model: SimpleRNN_Protein_SS_Model\n","============================================================\n","\n","--- Model Summary for SimpleRNN_Protein_SS_Model ---\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"SimpleRNN_Protein_SS_Model\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"SimpleRNN_Protein_SS_Model\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1231\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m5,440\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ RNN_Dropout (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1231\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ Output_Probabilities                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1231\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │             \u001b[38;5;34m195\u001b[0m │\n","│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1231</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">5,440</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ RNN_Dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1231</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ Output_Probabilities                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1231</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,635\u001b[0m (22.01 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,635</span> (22.01 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,635\u001b[0m (22.01 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,635</span> (22.01 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Total number of parameters to optimize: 5,635\n","============================================================\n","\n","============================================================\n","Building Model: LSTM_Protein_SS_Model\n","============================================================\n","\n","--- Model Summary for LSTM_Protein_SS_Model ---\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"LSTM_Protein_SS_Model\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"LSTM_Protein_SS_Model\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1231\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m21,760\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ RNN_Dropout (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1231\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ Output_Probabilities                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1231\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │             \u001b[38;5;34m195\u001b[0m │\n","│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1231</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">21,760</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ RNN_Dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1231</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ Output_Probabilities                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1231</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,955\u001b[0m (85.76 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,955</span> (85.76 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,955\u001b[0m (85.76 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,955</span> (85.76 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Total number of parameters to optimize: 21,955\n","============================================================\n","\n","============================================================\n","Building Model: GRU_Protein_SS_Model\n","============================================================\n","\n","--- Model Summary for GRU_Protein_SS_Model ---\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"GRU_Protein_SS_Model\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"GRU_Protein_SS_Model\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1231\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │          \u001b[38;5;34m16,512\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ RNN_Dropout (\u001b[38;5;33mDropout\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1231\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ Output_Probabilities                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1231\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │             \u001b[38;5;34m195\u001b[0m │\n","│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1231</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ RNN_Dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1231</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ Output_Probabilities                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1231</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,707\u001b[0m (65.26 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,707</span> (65.26 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,707\u001b[0m (65.26 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,707</span> (65.26 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Total number of parameters to optimize: 16,707\n","============================================================\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Input, SimpleRNN, LSTM, GRU, Dense, TimeDistributed, Dropout, Bidirectional\n","# Make sure variables from Part I are defined before running this:\n","# Example placeholders (replace with actual values from your Part I output):\n","# max_len = 1231\n","# NUM_AMINO_ACIDS = 20\n","# NUM_SECONDARY_STRUCTURES = 3\n","\n","# --- Check if variables are defined ---\n","try:\n","    # These should be defined from the previous part's execution\n","    _ = max_len\n","    _ = NUM_AMINO_ACIDS\n","    _ = NUM_SECONDARY_STRUCTURES\n","    print(f\"Using variables from Part I: max_len={max_len}, NUM_AMINO_ACIDS={NUM_AMINO_ACIDS}, NUM_SECONDARY_STRUCTURES={NUM_SECONDARY_STRUCTURES}\")\n","except NameError:\n","    print(\"\\n--- WARNING ---\")\n","    print(\"Variables `max_len`, `NUM_AMINO_ACIDS`, `NUM_SECONDARY_STRUCTURES` not found.\")\n","    print(\"Please ensure Part I code has been run and these variables are defined.\")\n","    print(\"Using placeholder values for demonstration purposes ONLY.\")\n","    print(\"You MUST replace these with your actual data dimensions for correct results.\")\n","    max_len = 500  # Example Placeholder - REPLACE\n","    NUM_AMINO_ACIDS = 20 # Example Placeholder - REPLACE\n","    NUM_SECONDARY_STRUCTURES = 3 # Example Placeholder - REPLACE\n","    print(f\"Using PLACEHOLDERS: max_len={max_len}, NUM_AMINO_ACIDS={NUM_AMINO_ACIDS}, NUM_SECONDARY_STRUCTURES={NUM_SECONDARY_STRUCTURES}\")\n","    print(\"---------------\\n\")\n","\n","\n","# Define RNN unit size (a hyperparameter you can tune)\n","RNN_UNITS = 64 # You can experiment with values like 32, 64, 128, 256\n","DROPOUT_RATE = 0.3 # Optional dropout for regularization\n","\n","# Helper function to build and report model\n","def build_and_report_rnn_model(model_type, units, dropout_rate, input_shape, output_classes):\n","    \"\"\"Builds, compiles, and prints the summary for a given RNN type.\"\"\"\n","    if model_type == 'SimpleRNN':\n","        rnn_layer = SimpleRNN(units, return_sequences=True)\n","        model_name = 'SimpleRNN_Protein_SS_Model'\n","    elif model_type == 'LSTM':\n","        rnn_layer = LSTM(units, return_sequences=True)\n","        model_name = 'LSTM_Protein_SS_Model'\n","    elif model_type == 'GRU':\n","        rnn_layer = GRU(units, return_sequences=True)\n","        model_name = 'GRU_Protein_SS_Model'\n","    # Optional: Bidirectional Wrapper\n","    #elif model_type == 'BiLSTM':\n","    #    rnn_layer = Bidirectional(LSTM(units, return_sequences=True))\n","    #    model_name = 'BiLSTM_Protein_SS_Model'\n","    else:\n","        raise ValueError(\"Unsupported model_type. Choose 'SimpleRNN', 'LSTM', or 'GRU'.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(f\"Building Model: {model_name}\")\n","    print(\"=\"*60)\n","\n","    model = Sequential(name=model_name)\n","    # Define Input Layer explicitly\n","    model.add(Input(shape=input_shape, name='Input_Sequence'))\n","\n","    # --- RNN Layer ---\n","    # return_sequences=True is CRUCIAL for many-to-many prediction\n","    # It makes the RNN output a sequence of shape (batch, timesteps, units)\n","    # instead of just the final state (batch, units)\n","    model.add(rnn_layer)\n","\n","    # Optional Dropout layer for regularization\n","    if dropout_rate > 0:\n","        model.add(Dropout(dropout_rate, name='RNN_Dropout'))\n","\n","    # --- Output Layer ---\n","    # We need to apply a Dense layer independently to each time step's output.\n","    # TimeDistributed wrapper does exactly this.\n","    # Output units = number of secondary structure classes (3)\n","    # Activation = softmax for multi-class probability output per time step\n","    model.add(TimeDistributed(Dense(output_classes, activation='softmax'), name='Output_Probabilities'))\n","\n","    # --- Compile the Model ---\n","    # Loss function: categorical_crossentropy is standard for multi-class, one-hot encoded labels with softmax output.\n","    # Optimizer: Adam is a good default choice.\n","    # Metrics: Accuracy measures the fraction of correctly predicted labels per time step.\n","    # Note on Accuracy with Padding: Standard accuracy might be slightly inflated if padding isn't masked.\n","    # For more rigorous evaluation, consider using masked loss/metrics or sample weighting if padding is significant.\n","    model.compile(optimizer='adam',\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy']) # Can add other metrics like tf.keras.metrics.Precision(), etc.\n","\n","    # --- Report Summary ---\n","    print(f\"\\n--- Model Summary for {model_name} ---\")\n","    model.summary() # Prints layer details and parameter counts\n","\n","    # Explicitly report total parameters\n","    total_params = model.count_params()\n","    print(f\"\\nTotal number of parameters to optimize: {total_params:,}\") # Use comma for readability\n","    print(\"=\"*60)\n","\n","    return model\n","\n","# Common input shape: (sequence_length, features_per_step)\n","input_shape = (max_len, NUM_AMINO_ACIDS)\n","output_classes = NUM_SECONDARY_STRUCTURES\n","\n","# =====================================================\n","# Task 1: Create and Report the three RNN Models\n","# =====================================================\n","\n","# 1. SimpleRNN Model\n","model_simple_rnn = build_and_report_rnn_model(\n","    model_type='SimpleRNN',\n","    units=RNN_UNITS,\n","    dropout_rate=DROPOUT_RATE,\n","    input_shape=input_shape,\n","    output_classes=output_classes\n",")\n","\n","# 2. LSTM Model\n","model_lstm = build_and_report_rnn_model(\n","    model_type='LSTM',\n","    units=RNN_UNITS,\n","    dropout_rate=DROPOUT_RATE,\n","    input_shape=input_shape,\n","    output_classes=output_classes\n",")\n","\n","# 3. GRU Model\n","model_gru = build_and_report_rnn_model(\n","    model_type='GRU',\n","    units=RNN_UNITS,\n","    dropout_rate=DROPOUT_RATE,\n","    input_shape=input_shape,\n","    output_classes=output_classes\n",")\n","\n","# You can also optionally explore a Bidirectional model:\n","# model_bilstm = build_and_report_rnn_model(\n","#     model_type='BiLSTM',\n","#     units=RNN_UNITS,\n","#     dropout_rate=DROPOUT_RATE,\n","#     input_shape=input_shape,\n","#     output_classes=output_classes\n","# )"]},{"cell_type":"markdown","metadata":{"id":"ubnVixp8gpwK"},"source":["###TASK - 2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":398451,"status":"ok","timestamp":1743704425614,"user":{"displayName":"Matthew Mueller","userId":"09372831935304640262"},"user_tz":300},"id":"Nd0wOVN3hHY9","outputId":"edad1e41-d6d6-4adc-e5b1-611dd98ffcbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Part II - Task 2: Test Model Training with Simulated Data\n","============================================================\n","Using variables and models defined in previous steps:\n","  max_len=1231, NUM_AMINO_ACIDS=20, NUM_SECONDARY_STRUCTURES=3\n","  Models: SimpleRNN_Protein_SS_Model, LSTM_Protein_SS_Model, GRU_Protein_SS_Model\n","\n","Generating simulated data with 32 samples...\n","Generating random indices for X...\n","Converting X indices to one-hot...\n","X_sim intermediate dtype: float64, final dtype: float32\n","Generating random indices for Y...\n","Converting Y indices to one-hot...\n","Y_sim intermediate dtype: float64, final dtype: float32\n","\n","Simulated data generated:\n","  X_sim shape: (32, 1231, 20), X_sim dtype: float32\n","  Y_sim shape: (32, 1231, 3), Y_sim dtype: float32\n","\n","Testing model training for 2 epochs with batch size 16...\n","\n","--- Testing Training for: SimpleRNN_Protein_SS_Model ---\n","Epoch 1/2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 152ms/step - accuracy: 0.3345 - loss: 1.1742\n","Epoch 2/2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.3376 - loss: 1.1607\n","\n","[SUCCESS] Training simulation completed without errors for SimpleRNN_Protein_SS_Model.\n","\n","--- Testing Training for: LSTM_Protein_SS_Model ---\n","Epoch 1/2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 226ms/step - accuracy: 0.3400 - loss: 1.0994\n","Epoch 2/2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 0.3365 - loss: 1.0993\n","\n","[SUCCESS] Training simulation completed without errors for LSTM_Protein_SS_Model.\n","\n","--- Testing Training for: GRU_Protein_SS_Model ---\n","Epoch 1/2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 211ms/step - accuracy: 0.3359 - loss: 1.1015\n","Epoch 2/2\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.3326 - loss: 1.1006\n","\n","[SUCCESS] Training simulation completed without errors for GRU_Protein_SS_Model.\n","\n","============================================================\n","Task 2 Requirement Met: All models successfully completed the training simulation loop without errors.\n","============================================================\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","\n","# --- Configuration ---\n","NUM_SIMULATED_SAMPLES = 32 # Number of random sequences to generate for testing\n","BATCH_SIZE_SIM = 16      # Batch size for simulated training\n","EPOCHS_SIM = 2           # Number of epochs for simulated training (just need 1 or 2)\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"Part II - Task 2: Test Model Training with Simulated Data\")\n","print(\"=\"*60)\n","\n","# --- Reuse Variables from Part I & Models from Part II Task 1 ---\n","# Ensure these variables and models are defined from previous steps.\n","try:\n","    # Variables from Part I\n","    _ = max_len\n","    _ = NUM_AMINO_ACIDS\n","    _ = NUM_SECONDARY_STRUCTURES\n","    # Models from Part II, Task 1\n","    _ = model_simple_rnn\n","    _ = model_lstm\n","    _ = model_gru\n","    print(\"Using variables and models defined in previous steps:\")\n","    print(f\"  max_len={max_len}, NUM_AMINO_ACIDS={NUM_AMINO_ACIDS}, NUM_SECONDARY_STRUCTURES={NUM_SECONDARY_STRUCTURES}\")\n","    print(f\"  Models: {model_simple_rnn.name}, {model_lstm.name}, {model_gru.name}\")\n","    models_to_test = {\n","        \"SimpleRNN\": model_simple_rnn,\n","        \"LSTM\": model_lstm,\n","        \"GRU\": model_gru\n","    }\n","except NameError as e:\n","    print(\"\\n--- ERROR ---\")\n","    print(f\"Variable or Model not found: {e}\")\n","    print(\"Please ensure Part I (data preparation) and Part II Task 1 (model definition)\")\n","    print(\"have been executed successfully in the same session before running this task.\")\n","    print(\"Cannot proceed with simulated training test.\")\n","    print(\"-------------\")\n","    # Exit or handle appropriately if models/vars aren't defined\n","    exit() # Or raise an exception\n","\n","# --- Step 1: Generate Simulated Data ---\n","print(f\"\\nGenerating simulated data with {NUM_SIMULATED_SAMPLES} samples...\")\n","\n","# Simulate Input X: (num_samples, max_len, NUM_AMINO_ACIDS)\n","# Generate random integer indices for amino acids (0 to NUM_AMINO_ACIDS-1)\n","print(\"Generating random indices for X...\")\n","x_indices_sim = np.random.randint(0, NUM_AMINO_ACIDS,\n","                                  size=(NUM_SIMULATED_SAMPLES, max_len),\n","                                  dtype=np.int32) # Specify int dtype for indices\n","\n","# Convert indices to one-hot encoding (default dtype might be float64)\n","print(\"Converting X indices to one-hot...\")\n","X_sim_temp = tf.keras.utils.to_categorical(x_indices_sim, num_classes=NUM_AMINO_ACIDS)\n","# Explicitly cast to float32\n","X_sim = X_sim_temp.astype(np.float32)\n","print(f\"X_sim intermediate dtype: {X_sim_temp.dtype}, final dtype: {X_sim.dtype}\")\n","\n","\n","# Simulate Output Y: (num_samples, max_len, NUM_SECONDARY_STRUCTURES)\n","# Generate random integer indices for secondary structures (0 to NUM_SECONDARY_STRUCTURES-1)\n","print(\"Generating random indices for Y...\")\n","y_indices_sim = np.random.randint(0, NUM_SECONDARY_STRUCTURES,\n","                                  size=(NUM_SIMULATED_SAMPLES, max_len),\n","                                  dtype=np.int32) # Specify int dtype for indices\n","\n","# Convert indices to one-hot encoding (default dtype might be float64)\n","print(\"Converting Y indices to one-hot...\")\n","Y_sim_temp = tf.keras.utils.to_categorical(y_indices_sim, num_classes=NUM_SECONDARY_STRUCTURES)\n","# Explicitly cast to float32\n","Y_sim = Y_sim_temp.astype(np.float32)\n","print(f\"Y_sim intermediate dtype: {Y_sim_temp.dtype}, final dtype: {Y_sim.dtype}\")\n","\n","\n","print(f\"\\nSimulated data generated:\")\n","print(f\"  X_sim shape: {X_sim.shape}, X_sim dtype: {X_sim.dtype}\") # Should be (NUM_SAMPLES, max_len, NUM_AA), float32\n","print(f\"  Y_sim shape: {Y_sim.shape}, Y_sim dtype: {Y_sim.dtype}\") # Should be (NUM_SAMPLES, max_len, NUM_SS), float32\n","\n","\n","# --- Step 2: Test Training for Each Model ---\n","print(f\"\\nTesting model training for {EPOCHS_SIM} epochs with batch size {BATCH_SIZE_SIM}...\")\n","\n","training_successful = True # Flag to track overall success\n","\n","for model_name, model in models_to_test.items():\n","    print(f\"\\n--- Testing Training for: {model.name} ---\")\n","    try:\n","        history = model.fit(\n","            X_sim,              # Simulated input features\n","            Y_sim,              # Simulated output labels\n","            epochs=EPOCHS_SIM,\n","            batch_size=BATCH_SIZE_SIM,\n","            verbose=1           # Show progress bar (1) or epoch results (2)\n","        )\n","        print(f\"\\n[SUCCESS] Training simulation completed without errors for {model.name}.\")\n","        # Optional: Print last epoch loss/accuracy\n","        # last_epoch = len(history.history['loss']) - 1\n","        # print(f\"  Final simulated loss: {history.history['loss'][last_epoch]:.4f}\")\n","        # print(f\"  Final simulated accuracy: {history.history['accuracy'][last_epoch]:.4f}\")\n","\n","    except Exception as e:\n","        print(f\"\\n[FAILURE] An error occurred during training simulation for {model.name}:\")\n","        print(f\"  Error Type: {type(e).__name__}\")\n","        print(f\"  Error Message: {e}\")\n","        import traceback\n","        traceback.print_exc() # Print full traceback for debugging\n","        training_successful = False # Mark overall test as failed\n","\n","print(\"\\n\" + \"=\"*60)\n","if training_successful:\n","    print(\"Task 2 Requirement Met: All models successfully completed the training simulation loop without errors.\")\n","else:\n","    print(\"Task 2 Requirement NOT Met: One or more models encountered errors during the training simulation.\")\n","print(\"=\"*60)"]},{"cell_type":"markdown","metadata":{"id":"kQ7l7mMmgron"},"source":["###TASK - 3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1693098,"status":"ok","timestamp":1743708691862,"user":{"displayName":"Matthew Mueller","userId":"09372831935304640262"},"user_tz":300},"id":"fqVwg_QahL7X","outputId":"f56c2ad9-3fba-4054-a869-501e3d57e041"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Part II - Task 3: Train and Evaluate Models on Real Data\n","============================================================\n","Successfully loaded data and models from previous parts.\n","Training data shape: X=(932, 1231, 20), Y=(932, 1231, 3)\n","Validation data shape: X=(234, 1231, 20), Y=(234, 1231, 3)\n","Test data shape: X=(124, 1231, 20), Y=(124, 1231, 3)\n","\n","############################################################\n","# Training Model: SimpleRNN_Protein_SS_Model\n","############################################################\n","Epoch 1/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m627s\u001b[0m 13s/step - accuracy: 0.4506 - loss: 0.2173 - val_accuracy: 0.3362 - val_loss: 0.2008\n","Epoch 2/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 100ms/step - accuracy: 0.3322 - loss: 0.1982 - val_accuracy: 0.8610 - val_loss: 0.1941\n","Epoch 3/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.3783 - loss: 0.1917 - val_accuracy: 0.1120 - val_loss: 0.1892\n","Epoch 4/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.1680 - loss: 0.1829 - val_accuracy: 0.1191 - val_loss: 0.1882\n","Epoch 5/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.2434 - loss: 0.1822 - val_accuracy: 0.9030 - val_loss: 0.1894\n","Epoch 6/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.5301 - loss: 0.1858 - val_accuracy: 0.1152 - val_loss: 0.1870\n","Epoch 7/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.1637 - loss: 0.1827 - val_accuracy: 0.1312 - val_loss: 0.1873\n","Epoch 8/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.3210 - loss: 0.1896 - val_accuracy: 0.1187 - val_loss: 0.1888\n","Epoch 9/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.2375 - loss: 0.1784 - val_accuracy: 0.1218 - val_loss: 0.1867\n","Epoch 10/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.1790 - loss: 0.1821 - val_accuracy: 0.9062 - val_loss: 0.1882\n","Epoch 11/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.3092 - loss: 0.1811 - val_accuracy: 0.1185 - val_loss: 0.1856\n","Epoch 12/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.1578 - loss: 0.1803 - val_accuracy: 0.1571 - val_loss: 0.1859\n","Epoch 13/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.1721 - loss: 0.1877 - val_accuracy: 0.1161 - val_loss: 0.1868\n","Epoch 14/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.1432 - loss: 0.1777 - val_accuracy: 0.1199 - val_loss: 0.1856\n","Epoch 15/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.2238 - loss: 0.1839 - val_accuracy: 0.3490 - val_loss: 0.1849\n","Epoch 16/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.2849 - loss: 0.1933 - val_accuracy: 0.1186 - val_loss: 0.1847\n","Epoch 17/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 96ms/step - accuracy: 0.2572 - loss: 0.1826 - val_accuracy: 0.3661 - val_loss: 0.1843\n","Epoch 18/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.2767 - loss: 0.1839 - val_accuracy: 0.3043 - val_loss: 0.1853\n","Epoch 19/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - accuracy: 0.3277 - loss: 0.1816 - val_accuracy: 0.4802 - val_loss: 0.1863\n","Epoch 20/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 97ms/step - accuracy: 0.3098 - loss: 0.1807 - val_accuracy: 0.3417 - val_loss: 0.1846\n","Restoring model weights from the end of the best epoch: 17.\n","\n","--- Finished Training SimpleRNN_Protein_SS_Model ---\n","\n","--- Evaluating on Training Set ---\n","  Keras Evaluate -> Loss: 0.1804, Accuracy (potentially includes padding): 0.3470\n","  Generating predictions...\n","  Total time steps: 1147292, Non-padded steps: 222287\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.5596\n","    Precision: 0.5558\n","    Recall:    0.5596\n","    F1-score:  0.5514\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.5835    0.6451    0.6128     94285\n","           H     0.5446    0.6000    0.5710     81251\n","           E     0.5194    0.3170    0.3937     46751\n","\n","    accuracy                         0.5596    222287\n","   macro avg     0.5492    0.5207    0.5258    222287\n","weighted avg     0.5558    0.5596    0.5514    222287\n","\n","\n","--- Evaluating on Validation Set ---\n","  Keras Evaluate -> Loss: 0.1843, Accuracy (potentially includes padding): 0.3661\n","  Generating predictions...\n","  Total time steps: 288054, Non-padded steps: 57068\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.5632\n","    Precision: 0.5593\n","    Recall:    0.5632\n","    F1-score:  0.5553\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.5913    0.6492    0.6189     24391\n","           H     0.5442    0.6020    0.5716     20567\n","           E     0.5207    0.3239    0.3994     12110\n","\n","    accuracy                         0.5632     57068\n","   macro avg     0.5520    0.5251    0.5300     57068\n","weighted avg     0.5593    0.5632    0.5553     57068\n","\n","\n","--- Evaluating on Test Set ---\n","  Keras Evaluate -> Loss: 0.1387, Accuracy (potentially includes padding): 0.4407\n","  Generating predictions...\n","  Total time steps: 152644, Non-padded steps: 22423\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.5526\n","    Precision: 0.5482\n","    Recall:    0.5526\n","    F1-score:  0.5449\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.5955    0.6601    0.6262     10083\n","           H     0.5109    0.5623    0.5354      7121\n","           E     0.5075    0.3315    0.4010      5219\n","\n","    accuracy                         0.5526     22423\n","   macro avg     0.5380    0.5180    0.5208     22423\n","weighted avg     0.5482    0.5526    0.5449     22423\n","\n","\n","############################################################\n","# Training Model: LSTM_Protein_SS_Model\n","############################################################\n","Epoch 1/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 782ms/step - accuracy: 0.7182 - loss: 0.2081 - val_accuracy: 0.8937 - val_loss: 0.2052\n","Epoch 2/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 270ms/step - accuracy: 0.8853 - loss: 0.2021 - val_accuracy: 0.8947 - val_loss: 0.1990\n","Epoch 3/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - accuracy: 0.8662 - loss: 0.1943 - val_accuracy: 0.9023 - val_loss: 0.1960\n","Epoch 4/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 270ms/step - accuracy: 0.8989 - loss: 0.1890 - val_accuracy: 0.9038 - val_loss: 0.1918\n","Epoch 5/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 274ms/step - accuracy: 0.8679 - loss: 0.1908 - val_accuracy: 0.9037 - val_loss: 0.1890\n","Epoch 6/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - accuracy: 0.8386 - loss: 0.1855 - val_accuracy: 0.9102 - val_loss: 0.1883\n","Epoch 7/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 270ms/step - accuracy: 0.8732 - loss: 0.1838 - val_accuracy: 0.8991 - val_loss: 0.1862\n","Epoch 8/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 271ms/step - accuracy: 0.8873 - loss: 0.1879 - val_accuracy: 0.8910 - val_loss: 0.1847\n","Epoch 9/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 273ms/step - accuracy: 0.8622 - loss: 0.1797 - val_accuracy: 0.9059 - val_loss: 0.1866\n","Epoch 10/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 270ms/step - accuracy: 0.8877 - loss: 0.1864 - val_accuracy: 0.8577 - val_loss: 0.1847\n","Epoch 11/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 270ms/step - accuracy: 0.8428 - loss: 0.1814 - val_accuracy: 0.8848 - val_loss: 0.1835\n","Epoch 12/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 268ms/step - accuracy: 0.8932 - loss: 0.1852 - val_accuracy: 0.8986 - val_loss: 0.1847\n","Epoch 13/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 268ms/step - accuracy: 0.9009 - loss: 0.1814 - val_accuracy: 0.8893 - val_loss: 0.1832\n","Epoch 14/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 270ms/step - accuracy: 0.8905 - loss: 0.1794 - val_accuracy: 0.8915 - val_loss: 0.1832\n","Epoch 15/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 271ms/step - accuracy: 0.8870 - loss: 0.1781 - val_accuracy: 0.8953 - val_loss: 0.1826\n","Epoch 16/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 271ms/step - accuracy: 0.8930 - loss: 0.1858 - val_accuracy: 0.8455 - val_loss: 0.1835\n","Epoch 17/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 272ms/step - accuracy: 0.8803 - loss: 0.1777 - val_accuracy: 0.8862 - val_loss: 0.1821\n","Epoch 18/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 272ms/step - accuracy: 0.8822 - loss: 0.1816 - val_accuracy: 0.8834 - val_loss: 0.1820\n","Epoch 19/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 266ms/step - accuracy: 0.8421 - loss: 0.1766 - val_accuracy: 0.8919 - val_loss: 0.1818\n","Epoch 20/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 269ms/step - accuracy: 0.8929 - loss: 0.1761 - val_accuracy: 0.8819 - val_loss: 0.1814\n","Restoring model weights from the end of the best epoch: 20.\n","\n","--- Finished Training LSTM_Protein_SS_Model ---\n","\n","--- Evaluating on Training Set ---\n","  Keras Evaluate -> Loss: 0.1766, Accuracy (potentially includes padding): 0.8821\n","  Generating predictions...\n","  Total time steps: 1147292, Non-padded steps: 222287\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.5701\n","    Precision: 0.5666\n","    Recall:    0.5701\n","    F1-score:  0.5659\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.5865    0.6489    0.6161     94285\n","           H     0.5727    0.5820    0.5773     81251\n","           E     0.5158    0.3907    0.4446     46751\n","\n","    accuracy                         0.5701    222287\n","   macro avg     0.5583    0.5405    0.5460    222287\n","weighted avg     0.5666    0.5701    0.5659    222287\n","\n","\n","--- Evaluating on Validation Set ---\n","  Keras Evaluate -> Loss: 0.1814, Accuracy (potentially includes padding): 0.8819\n","  Generating predictions...\n","  Total time steps: 288054, Non-padded steps: 57068\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.5702\n","    Precision: 0.5663\n","    Recall:    0.5702\n","    F1-score:  0.5660\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.5913    0.6484    0.6185     24391\n","           H     0.5707    0.5832    0.5769     20567\n","           E     0.5084    0.3905    0.4417     12110\n","\n","    accuracy                         0.5702     57068\n","   macro avg     0.5568    0.5407    0.5457     57068\n","weighted avg     0.5663    0.5702    0.5660     57068\n","\n","\n","--- Evaluating on Test Set ---\n","  Keras Evaluate -> Loss: 0.1360, Accuracy (potentially includes padding): 0.9114\n","  Generating predictions...\n","  Total time steps: 152644, Non-padded steps: 22423\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.5611\n","    Precision: 0.5557\n","    Recall:    0.5611\n","    F1-score:  0.5562\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.5957    0.6711    0.6312     10083\n","           H     0.5484    0.5280    0.5380      7121\n","           E     0.4885    0.3938    0.4360      5219\n","\n","    accuracy                         0.5611     22423\n","   macro avg     0.5442    0.5310    0.5351     22423\n","weighted avg     0.5557    0.5611    0.5562     22423\n","\n","\n","############################################################\n","# Training Model: GRU_Protein_SS_Model\n","############################################################\n","Epoch 1/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 828ms/step - accuracy: 0.6354 - loss: 0.2110 - val_accuracy: 0.9013 - val_loss: 0.2025\n","Epoch 2/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 269ms/step - accuracy: 0.8807 - loss: 0.2005 - val_accuracy: 0.9040 - val_loss: 0.1940\n","Epoch 3/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 271ms/step - accuracy: 0.8803 - loss: 0.1902 - val_accuracy: 0.9085 - val_loss: 0.1898\n","Epoch 4/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - accuracy: 0.8961 - loss: 0.1889 - val_accuracy: 0.9103 - val_loss: 0.1875\n","Epoch 5/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 270ms/step - accuracy: 0.8597 - loss: 0.1823 - val_accuracy: 0.9106 - val_loss: 0.1867\n","Epoch 6/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 271ms/step - accuracy: 0.8094 - loss: 0.1809 - val_accuracy: 0.9107 - val_loss: 0.1863\n","Epoch 7/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 268ms/step - accuracy: 0.8537 - loss: 0.1861 - val_accuracy: 0.9111 - val_loss: 0.1863\n","Epoch 8/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - accuracy: 0.8327 - loss: 0.1809 - val_accuracy: 0.1154 - val_loss: 0.1859\n","Epoch 9/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 271ms/step - accuracy: 0.5082 - loss: 0.1830 - val_accuracy: 0.9113 - val_loss: 0.1856\n","Epoch 10/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 266ms/step - accuracy: 0.7676 - loss: 0.1839 - val_accuracy: 0.9115 - val_loss: 0.1858\n","Epoch 11/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - accuracy: 0.6998 - loss: 0.1869 - val_accuracy: 0.1179 - val_loss: 0.1850\n","Epoch 12/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 269ms/step - accuracy: 0.5012 - loss: 0.1865 - val_accuracy: 0.1162 - val_loss: 0.1847\n","Epoch 13/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - accuracy: 0.4799 - loss: 0.1805 - val_accuracy: 0.1142 - val_loss: 0.1844\n","Epoch 14/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 268ms/step - accuracy: 0.2012 - loss: 0.1844 - val_accuracy: 0.1171 - val_loss: 0.1840\n","Epoch 15/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - accuracy: 0.3816 - loss: 0.1785 - val_accuracy: 0.1122 - val_loss: 0.1851\n","Epoch 16/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 269ms/step - accuracy: 0.3623 - loss: 0.1858 - val_accuracy: 0.1133 - val_loss: 0.1839\n","Epoch 17/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 267ms/step - accuracy: 0.2777 - loss: 0.1820 - val_accuracy: 0.1148 - val_loss: 0.1836\n","Epoch 18/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 271ms/step - accuracy: 0.4473 - loss: 0.1804 - val_accuracy: 0.1187 - val_loss: 0.1821\n","Epoch 19/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 265ms/step - accuracy: 0.2699 - loss: 0.1789 - val_accuracy: 0.1231 - val_loss: 0.1815\n","Epoch 20/20\n","\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 269ms/step - accuracy: 0.2753 - loss: 0.1760 - val_accuracy: 0.1230 - val_loss: 0.1817\n","Restoring model weights from the end of the best epoch: 19.\n","\n","--- Finished Training GRU_Protein_SS_Model ---\n","\n","--- Evaluating on Training Set ---\n","  Keras Evaluate -> Loss: 0.1769, Accuracy (potentially includes padding): 0.1217\n","  Generating predictions...\n","  Total time steps: 1147292, Non-padded steps: 222287\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.5688\n","    Precision: 0.5656\n","    Recall:    0.5688\n","    F1-score:  0.5629\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.5899    0.6380    0.6130     94285\n","           H     0.5589    0.6095    0.5831     81251\n","           E     0.5284    0.3582    0.4270     46751\n","\n","    accuracy                         0.5688    222287\n","   macro avg     0.5590    0.5353    0.5410    222287\n","weighted avg     0.5656    0.5688    0.5629    222287\n","\n","\n","--- Evaluating on Validation Set ---\n","  Keras Evaluate -> Loss: 0.1815, Accuracy (potentially includes padding): 0.1231\n","  Generating predictions...\n","  Total time steps: 288054, Non-padded steps: 57068\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.5680\n","    Precision: 0.5646\n","    Recall:    0.5680\n","    F1-score:  0.5620\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.5942    0.6363    0.6145     24391\n","           H     0.5545    0.6138    0.5826     20567\n","           E     0.5224    0.3528    0.4212     12110\n","\n","    accuracy                         0.5680     57068\n","   macro avg     0.5570    0.5343    0.5394     57068\n","weighted avg     0.5646    0.5680    0.5620     57068\n","\n","\n","--- Evaluating on Test Set ---\n","  Keras Evaluate -> Loss: 0.1366, Accuracy (potentially includes padding): 0.0977\n","  Generating predictions...\n","  Total time steps: 152644, Non-padded steps: 22423\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.5543\n","    Precision: 0.5492\n","    Recall:    0.5543\n","    F1-score:  0.5488\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.5947    0.6561    0.6239     10083\n","           H     0.5249    0.5475    0.5360      7121\n","           E     0.4944    0.3667    0.4211      5219\n","\n","    accuracy                         0.5543     22423\n","   macro avg     0.5380    0.5234    0.5270     22423\n","weighted avg     0.5492    0.5543    0.5488     22423\n","\n","\n","======================================================================\n","Final Performance Summary\n","======================================================================\n","\n","--- SimpleRNN ---\n","  Training Set:\n","    Accuracy:  0.5596 (on non-padded steps)\n","    Precision: 0.5558\n","    Recall:    0.5596\n","    F1-score:  0.5514\n","    Loss:      0.1804\n","  Validation Set:\n","    Accuracy:  0.5632 (on non-padded steps)\n","    Precision: 0.5593\n","    Recall:    0.5632\n","    F1-score:  0.5553\n","    Loss:      0.1843\n","  Test Set:\n","    Accuracy:  0.5526 (on non-padded steps)\n","    Precision: 0.5482\n","    Recall:    0.5526\n","    F1-score:  0.5449\n","    Loss:      0.1387\n","----------------------------------------\n","\n","--- LSTM ---\n","  Training Set:\n","    Accuracy:  0.5701 (on non-padded steps)\n","    Precision: 0.5666\n","    Recall:    0.5701\n","    F1-score:  0.5659\n","    Loss:      0.1766\n","  Validation Set:\n","    Accuracy:  0.5702 (on non-padded steps)\n","    Precision: 0.5663\n","    Recall:    0.5702\n","    F1-score:  0.5660\n","    Loss:      0.1814\n","  Test Set:\n","    Accuracy:  0.5611 (on non-padded steps)\n","    Precision: 0.5557\n","    Recall:    0.5611\n","    F1-score:  0.5562\n","    Loss:      0.1360\n","----------------------------------------\n","\n","--- GRU ---\n","  Training Set:\n","    Accuracy:  0.5688 (on non-padded steps)\n","    Precision: 0.5656\n","    Recall:    0.5688\n","    F1-score:  0.5629\n","    Loss:      0.1769\n","  Validation Set:\n","    Accuracy:  0.5680 (on non-padded steps)\n","    Precision: 0.5646\n","    Recall:    0.5680\n","    F1-score:  0.5620\n","    Loss:      0.1815\n","  Test Set:\n","    Accuracy:  0.5543 (on non-padded steps)\n","    Precision: 0.5492\n","    Recall:    0.5543\n","    F1-score:  0.5488\n","    Loss:      0.1366\n","----------------------------------------\n","\n","======================================================================\n","Detailed Classification Reports (on non-padded steps)\n","======================================================================\n","\n","--- SimpleRNN ---\n","  Training Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.5835    0.6451    0.6128     94285\n","           H     0.5446    0.6000    0.5710     81251\n","           E     0.5194    0.3170    0.3937     46751\n","\n","    accuracy                         0.5596    222287\n","   macro avg     0.5492    0.5207    0.5258    222287\n","weighted avg     0.5558    0.5596    0.5514    222287\n","\n","--------------------\n","  Validation Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.5913    0.6492    0.6189     24391\n","           H     0.5442    0.6020    0.5716     20567\n","           E     0.5207    0.3239    0.3994     12110\n","\n","    accuracy                         0.5632     57068\n","   macro avg     0.5520    0.5251    0.5300     57068\n","weighted avg     0.5593    0.5632    0.5553     57068\n","\n","--------------------\n","  Test Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.5955    0.6601    0.6262     10083\n","           H     0.5109    0.5623    0.5354      7121\n","           E     0.5075    0.3315    0.4010      5219\n","\n","    accuracy                         0.5526     22423\n","   macro avg     0.5380    0.5180    0.5208     22423\n","weighted avg     0.5482    0.5526    0.5449     22423\n","\n","--------------------\n","----------------------------------------\n","\n","--- LSTM ---\n","  Training Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.5865    0.6489    0.6161     94285\n","           H     0.5727    0.5820    0.5773     81251\n","           E     0.5158    0.3907    0.4446     46751\n","\n","    accuracy                         0.5701    222287\n","   macro avg     0.5583    0.5405    0.5460    222287\n","weighted avg     0.5666    0.5701    0.5659    222287\n","\n","--------------------\n","  Validation Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.5913    0.6484    0.6185     24391\n","           H     0.5707    0.5832    0.5769     20567\n","           E     0.5084    0.3905    0.4417     12110\n","\n","    accuracy                         0.5702     57068\n","   macro avg     0.5568    0.5407    0.5457     57068\n","weighted avg     0.5663    0.5702    0.5660     57068\n","\n","--------------------\n","  Test Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.5957    0.6711    0.6312     10083\n","           H     0.5484    0.5280    0.5380      7121\n","           E     0.4885    0.3938    0.4360      5219\n","\n","    accuracy                         0.5611     22423\n","   macro avg     0.5442    0.5310    0.5351     22423\n","weighted avg     0.5557    0.5611    0.5562     22423\n","\n","--------------------\n","----------------------------------------\n","\n","--- GRU ---\n","  Training Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.5899    0.6380    0.6130     94285\n","           H     0.5589    0.6095    0.5831     81251\n","           E     0.5284    0.3582    0.4270     46751\n","\n","    accuracy                         0.5688    222287\n","   macro avg     0.5590    0.5353    0.5410    222287\n","weighted avg     0.5656    0.5688    0.5629    222287\n","\n","--------------------\n","  Validation Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.5942    0.6363    0.6145     24391\n","           H     0.5545    0.6138    0.5826     20567\n","           E     0.5224    0.3528    0.4212     12110\n","\n","    accuracy                         0.5680     57068\n","   macro avg     0.5570    0.5343    0.5394     57068\n","weighted avg     0.5646    0.5680    0.5620     57068\n","\n","--------------------\n","  Test Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.5947    0.6561    0.6239     10083\n","           H     0.5249    0.5475    0.5360      7121\n","           E     0.4944    0.3667    0.4211      5219\n","\n","    accuracy                         0.5543     22423\n","   macro avg     0.5380    0.5234    0.5270     22423\n","weighted avg     0.5492    0.5543    0.5488     22423\n","\n","--------------------\n","----------------------------------------\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n","import os  # <--- IMPORT OS MODULE HERE\n","\n","# --- Configuration ---\n","EPOCHS = 20          # Maximum number of epochs (EarlyStopping will likely stop it sooner)\n","BATCH_SIZE = 32      # Samples per gradient update\n","PATIENCE = 5         # How many epochs to wait for improvement before stopping early\n","MODEL_SAVE_DIR = \"saved_models\" # Directory to save best models (optional)\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"Part II - Task 3: Train and Evaluate Models on Real Data\")\n","print(\"=\"*60)\n","\n","# --- Ensure Data and Models Exist ---\n","try:\n","    # Data from Part I\n","    # ---> !!! THESE MUST EXIST FROM RUNNING PART I CODE FIRST !!! <---\n","    _ = X_train, Y_train, X_val, Y_val, X_test, Y_test\n","    # Models from Part II, Task 1\n","    # ---> !!! THESE MUST EXIST FROM RUNNING PART II TASK 1 CODE FIRST !!! <---\n","    _ = model_simple_rnn, model_lstm, model_gru\n","    # Variables from Part I\n","    # ---> !!! THESE MUST EXIST FROM RUNNING PART I CODE FIRST !!! <---\n","    _ = max_len, NUM_AMINO_ACIDS, NUM_SECONDARY_STRUCTURES\n","\n","    print(\"Successfully loaded data and models from previous parts.\")\n","    print(f\"Training data shape: X={X_train.shape}, Y={Y_train.shape}\")\n","    print(f\"Validation data shape: X={X_val.shape}, Y={Y_val.shape}\")\n","    print(f\"Test data shape: X={X_test.shape}, Y={Y_test.shape}\")\n","\n","    models_to_train = {\n","        \"SimpleRNN\": model_simple_rnn,\n","        \"LSTM\": model_lstm,\n","        \"GRU\": model_gru\n","    }\n","    datasets = {\n","        \"Training\": (X_train, Y_train),\n","        \"Validation\": (X_val, Y_val),\n","        \"Test\": (X_test, Y_test)\n","    }\n","    results = {} # To store evaluation results\n","\n","except NameError as e:\n","    print(\"\\n--- ERROR ---\")\n","    print(f\"Variable or Model not found: {e}\")\n","    print(\"Please ensure Part I (data prep) and Part II Task 1 (model definition)\")\n","    print(\"have been executed successfully in the same session before running this task.\")\n","    print(\"Cannot proceed with training.\")\n","    print(\"-------------\")\n","    # Ensure exit() is uncommented or handle appropriately if running interactively\n","    exit() # Stop if setup is incomplete\n","\n","# --- Helper Function for Masked Evaluation ---\n","# (Keep the evaluate_model_performance function exactly as defined before)\n","def evaluate_model_performance(model, x_data, y_data, dataset_name):\n","    \"\"\"Evaluates model, handling padding for precise metrics.\"\"\"\n","    print(f\"\\n--- Evaluating on {dataset_name} Set ---\")\n","\n","    # 1. Get Loss and Accuracy (Keras handles masking internally if supported, but generally okay for overall accuracy)\n","    loss, accuracy = model.evaluate(x_data, y_data, verbose=0, batch_size=BATCH_SIZE) # Added batch_size\n","    print(f\"  Keras Evaluate -> Loss: {loss:.4f}, Accuracy (potentially includes padding): {accuracy:.4f}\")\n","\n","    # 2. Get Predictions (Probabilities)\n","    print(\"  Generating predictions...\")\n","    y_pred_prob = model.predict(x_data, batch_size=BATCH_SIZE, verbose=0) # Shape: (N, L, 3)\n","\n","    # 3. Convert Probabilities and True Labels to Class Indices\n","    y_pred_indices = np.argmax(y_pred_prob, axis=-1) # Shape: (N, L)\n","    y_true_indices = np.argmax(y_data, axis=-1)     # Shape: (N, L)\n","\n","    # 4. Create Mask to Ignore Padding\n","    # Padded input features (X) are all zeros. Sum across feature dim. If sum > 0, it's not padding.\n","    mask = np.sum(x_data, axis=-1) > 1e-6  # Use a small threshold for float comparison Shape: (N, L)\n","\n","    # 5. Flatten arrays and apply mask\n","    y_pred_flat_masked = y_pred_indices[mask]\n","    y_true_flat_masked = y_true_indices[mask]\n","\n","    print(f\"  Total time steps: {mask.size}, Non-padded steps: {np.sum(mask)}\")\n","    if np.sum(mask) == 0:\n","        print(\"  Warning: No non-padded steps found based on input mask. Cannot calculate detailed metrics.\")\n","        # Return metrics based on Keras evaluation if available, otherwise Nones\n","        return {\n","            \"loss\": loss,\n","            \"accuracy_keras\": accuracy,\n","            \"accuracy\": 0.0 if accuracy is not None else None, # Avoid error if loss/acc were None\n","            \"precision\": 0.0,\n","            \"recall\": 0.0,\n","            \"f1_score\": 0.0,\n","            \"report\": \"No non-padded steps\"}\n","\n","    # 6. Calculate Detailed Metrics (Precision, Recall, F1) on *masked* data\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        y_true_flat_masked,\n","        y_pred_flat_masked,\n","        average='weighted',\n","        zero_division=0\n","    )\n","    accuracy_masked = accuracy_score(y_true_flat_masked, y_pred_flat_masked)\n","\n","    print(f\"  Metrics (on non-padded steps):\")\n","    print(f\"    Accuracy:  {accuracy_masked:.4f}\")\n","    print(f\"    Precision: {precision:.4f}\")\n","    print(f\"    Recall:    {recall:.4f}\")\n","    print(f\"    F1-score:  {f1:.4f}\")\n","\n","    # 7. Optional: Classification Report (per class)\n","    try:\n","        # Generate target names dynamically based on NUM_SECONDARY_STRUCTURES if needed\n","        # Defaulting to ['C', 'H', 'E'] based on previous context\n","        target_names_list = list(SECONDARY_STRUCTURES) if 'SECONDARY_STRUCTURES' in globals() else [f'Class_{i}' for i in range(NUM_SECONDARY_STRUCTURES)]\n","\n","        report = classification_report(\n","            y_true_flat_masked,\n","            y_pred_flat_masked,\n","            target_names=target_names_list,\n","            digits=4, # Increase precision in report\n","            zero_division=0\n","        )\n","        print(\"  Classification Report (on non-padded steps):\\n\", report)\n","    except Exception as report_err:\n","        print(f\"  Could not generate classification report: {report_err}\")\n","        report = \"Error generating report\"\n","\n","    return {\n","        \"loss\": loss,\n","        \"accuracy_keras\": accuracy,\n","        \"accuracy\": accuracy_masked,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"f1_score\": f1,\n","        \"report\": report\n","    }\n","\n","\n","# --- Create directory for saving models (optional) ---\n","if not os.path.exists(MODEL_SAVE_DIR):\n","    try:\n","        os.makedirs(MODEL_SAVE_DIR)\n","        print(f\"Created directory for saving models: {MODEL_SAVE_DIR}\")\n","    except OSError as e:\n","        print(f\"Error creating directory {MODEL_SAVE_DIR}: {e}\")\n","        # Decide if this is critical - maybe proceed without saving?\n","        # exit()\n","\n","# --- Train and Evaluate Each Model ---\n","# (Keep the training and evaluation loop exactly as defined before)\n","for model_name, model in models_to_train.items():\n","    print(\"\\n\" + \"#\"*60)\n","    print(f\"# Training Model: {model.name}\")\n","    print(\"#\"*60)\n","\n","    # Define Callbacks\n","    early_stopping = EarlyStopping(\n","        monitor='val_loss',\n","        patience=PATIENCE,\n","        verbose=1,\n","        restore_best_weights=True\n","    )\n","    callbacks_list = [early_stopping]\n","\n","    # Train the Model\n","    history = model.fit(\n","        X_train, Y_train,\n","        epochs=EPOCHS,\n","        batch_size=BATCH_SIZE,\n","        validation_data=(X_val, Y_val),\n","        callbacks=callbacks_list,\n","        verbose=1\n","    )\n","\n","    print(f\"\\n--- Finished Training {model.name} ---\")\n","\n","    # Evaluate the Model\n","    model_results = {}\n","    for dataset_name, (x_data, y_data) in datasets.items():\n","         if dataset_name == \"Test\" and (x_data is None or x_data.shape[0] == 0): # Check x_data directly\n","             print(\"\\nSkipping evaluation on empty Test set.\")\n","             model_results[dataset_name] = {\"loss\": None, \"accuracy\": None, \"precision\": None, \"recall\": None, \"f1_score\": None, \"report\": \"Test set empty\"}\n","             continue\n","         # Ensure y_data also exists and has samples if x_data is valid\n","         if y_data is None or y_data.shape[0] == 0:\n","             print(f\"\\nSkipping evaluation on {dataset_name} set due to empty Y data.\")\n","             model_results[dataset_name] = {\"loss\": None, \"accuracy\": None, \"precision\": None, \"recall\": None, \"f1_score\": None, \"report\": f\"{dataset_name} set Y empty\"}\n","             continue\n","\n","         model_results[dataset_name] = evaluate_model_performance(model, x_data, y_data, dataset_name)\n","\n","    results[model_name] = model_results\n","\n","    # clear up GPU memory\n","    import gc\n","    tf.keras.backend.clear_session()\n","    gc.collect()\n","\n","# --- Requirement: Report Final Metrics ---\n","# (Keep the reporting section exactly as defined before)\n","print(\"\\n\" + \"=\"*70)\n","print(\"Final Performance Summary\")\n","print(\"=\"*70)\n","\n","for model_name, model_results in results.items():\n","    print(f\"\\n--- {model_name} ---\")\n","    for dataset_name, metrics in model_results.items():\n","        # Check if 'accuracy' exists and is not None before printing\n","        if 'accuracy' in metrics and metrics['accuracy'] is not None:\n","            print(f\"  {dataset_name} Set:\")\n","            print(f\"    Accuracy:  {metrics['accuracy']:.4f} (on non-padded steps)\")\n","            print(f\"    Precision: {metrics['precision']:.4f}\")\n","            print(f\"    Recall:    {metrics['recall']:.4f}\")\n","            print(f\"    F1-score:  {metrics['f1_score']:.4f}\")\n","            print(f\"    Loss:      {metrics['loss']:.4f}\")\n","        else:\n","            print(f\"  {dataset_name} Set: Not Evaluated ({metrics.get('report', 'Reason unknown')})\")\n","    print(\"-\" * 40)\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"Detailed Classification Reports (on non-padded steps)\")\n","print(\"=\"*70)\n","for model_name, model_results in results.items():\n","    print(f\"\\n--- {model_name} ---\")\n","    for dataset_name, metrics in model_results.items():\n","        # Check if 'report' exists and evaluation happened\n","        if 'report' in metrics and metrics['accuracy'] is not None:\n","             print(f\"  {dataset_name} Set Report:\")\n","             print(metrics['report'])\n","             print(\"-\" * 20)\n","        elif 'report' in metrics:\n","             print(f\"  {dataset_name} Set: Not Evaluated ({metrics['report']})\")\n","             print(\"-\" * 20)\n","    print(\"-\" * 40)"]},{"cell_type":"markdown","metadata":{"id":"F1to3HWTgsdf"},"source":["###TASK - 4"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"W7Xx_jxEyTTn","executionInfo":{"status":"ok","timestamp":1743715707141,"user_tz":300,"elapsed":1370087,"user":{"displayName":"Matthew Mueller","userId":"09372831935304640262"}},"outputId":"fb90d454-de55-4c75-c776-6296f06f1d53"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Part II - Task 4: Train and Evaluate Bidirectional Models\n","============================================================\n","Successfully loaded data, variables, evaluation function, and datasets dict from previous parts.\n","Input shape: (1231, 20), Output classes: 3\n","\n","============================================================\n","Building Model: BiLSTM_Protein_SS_Model\n","============================================================\n","\n","--- Model Summary for BiLSTM_Protein_SS_Model ---\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"BiLSTM_Protein_SS_Model\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"BiLSTM_Protein_SS_Model\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1231\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m43,520\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ BiRNN_Dropout (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1231\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ Output_Probabilities                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1231\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │             \u001b[38;5;34m387\u001b[0m │\n","│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1231</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">43,520</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ BiRNN_Dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1231</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ Output_Probabilities                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1231</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m43,907\u001b[0m (171.51 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,907</span> (171.51 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m43,907\u001b[0m (171.51 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">43,907</span> (171.51 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Total number of parameters to optimize: 43,907\n","============================================================\n","\n","============================================================\n","Building Model: BiGRU_Protein_SS_Model\n","============================================================\n","\n","--- Model Summary for BiGRU_Protein_SS_Model ---\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"BiGRU_Protein_SS_Model\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"BiGRU_Protein_SS_Model\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ bidirectional_3 (\u001b[38;5;33mBidirectional\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1231\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m33,024\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ BiRNN_Dropout (\u001b[38;5;33mDropout\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1231\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ Output_Probabilities                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1231\u001b[0m, \u001b[38;5;34m3\u001b[0m)             │             \u001b[38;5;34m387\u001b[0m │\n","│ (\u001b[38;5;33mTimeDistributed\u001b[0m)                    │                             │                 │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ bidirectional_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1231</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ BiRNN_Dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1231</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ Output_Probabilities                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1231</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n","│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)                    │                             │                 │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,411\u001b[0m (130.51 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,411</span> (130.51 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33,411\u001b[0m (130.51 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,411</span> (130.51 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Total number of parameters to optimize: 33,411\n","============================================================\n","\n","############################################################\n","# Training Model: BiLSTM_Protein_SS_Model\n","############################################################\n","Epoch 1/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 375ms/step - accuracy: 0.8957 - loss: 0.1932 - val_accuracy: 0.9116 - val_loss: 0.1832\n","Epoch 2/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 242ms/step - accuracy: 0.9170 - loss: 0.1753 - val_accuracy: 0.9237 - val_loss: 0.1692\n","Epoch 3/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 240ms/step - accuracy: 0.9234 - loss: 0.1664 - val_accuracy: 0.9240 - val_loss: 0.1678\n","Epoch 4/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 239ms/step - accuracy: 0.9258 - loss: 0.1618 - val_accuracy: 0.9269 - val_loss: 0.1628\n","Epoch 5/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 244ms/step - accuracy: 0.9273 - loss: 0.1606 - val_accuracy: 0.9270 - val_loss: 0.1630\n","Epoch 6/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 245ms/step - accuracy: 0.9281 - loss: 0.1600 - val_accuracy: 0.9286 - val_loss: 0.1608\n","Epoch 7/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 241ms/step - accuracy: 0.9267 - loss: 0.1635 - val_accuracy: 0.9293 - val_loss: 0.1593\n","Epoch 8/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 240ms/step - accuracy: 0.9335 - loss: 0.1485 - val_accuracy: 0.9296 - val_loss: 0.1583\n","Epoch 9/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 242ms/step - accuracy: 0.9319 - loss: 0.1530 - val_accuracy: 0.9286 - val_loss: 0.1589\n","Epoch 10/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 238ms/step - accuracy: 0.9325 - loss: 0.1520 - val_accuracy: 0.9299 - val_loss: 0.1575\n","Epoch 11/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 237ms/step - accuracy: 0.9325 - loss: 0.1528 - val_accuracy: 0.9289 - val_loss: 0.1600\n","Epoch 12/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 236ms/step - accuracy: 0.9323 - loss: 0.1525 - val_accuracy: 0.9312 - val_loss: 0.1554\n","Epoch 13/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 237ms/step - accuracy: 0.9329 - loss: 0.1520 - val_accuracy: 0.9311 - val_loss: 0.1561\n","Epoch 14/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 238ms/step - accuracy: 0.9319 - loss: 0.1546 - val_accuracy: 0.9315 - val_loss: 0.1554\n","Epoch 15/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 238ms/step - accuracy: 0.9352 - loss: 0.1463 - val_accuracy: 0.9321 - val_loss: 0.1543\n","Epoch 16/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 239ms/step - accuracy: 0.9330 - loss: 0.1514 - val_accuracy: 0.9320 - val_loss: 0.1551\n","Epoch 17/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 237ms/step - accuracy: 0.9332 - loss: 0.1517 - val_accuracy: 0.9320 - val_loss: 0.1542\n","Epoch 18/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 237ms/step - accuracy: 0.9339 - loss: 0.1504 - val_accuracy: 0.9320 - val_loss: 0.1541\n","Epoch 19/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 237ms/step - accuracy: 0.9355 - loss: 0.1466 - val_accuracy: 0.9322 - val_loss: 0.1539\n","Epoch 20/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 236ms/step - accuracy: 0.9337 - loss: 0.1495 - val_accuracy: 0.9321 - val_loss: 0.1539\n","Restoring model weights from the end of the best epoch: 19.\n","\n","--- Finished Training BiLSTM_Protein_SS_Model ---\n","\n","--- Evaluating on Training Set ---\n","  Keras Evaluate -> Loss: 0.1464, Accuracy (potentially includes padding): 0.9357\n","  Generating predictions...\n","  Total time steps: 1147292, Non-padded steps: 222287\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.6681\n","    Precision: 0.6673\n","    Recall:    0.6681\n","    F1-score:  0.6635\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.6744    0.7140    0.6936     94285\n","           H     0.6659    0.7315    0.6972     81251\n","           E     0.6551    0.4655    0.5443     46751\n","\n","    accuracy                         0.6681    222287\n","   macro avg     0.6652    0.6370    0.6450    222287\n","weighted avg     0.6673    0.6681    0.6635    222287\n","\n","\n","--- Evaluating on Validation Set ---\n","  Keras Evaluate -> Loss: 0.1539, Accuracy (potentially includes padding): 0.9322\n","  Generating predictions...\n","  Total time steps: 288054, Non-padded steps: 57068\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.6577\n","    Precision: 0.6559\n","    Recall:    0.6577\n","    F1-score:  0.6521\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.6733    0.7087    0.6905     24391\n","           H     0.6502    0.7266    0.6863     20567\n","           E     0.6307    0.4379    0.5169     12110\n","\n","    accuracy                         0.6577     57068\n","   macro avg     0.6514    0.6244    0.6312     57068\n","weighted avg     0.6559    0.6577    0.6521     57068\n","\n","\n","--- Evaluating on Test Set ---\n","  Keras Evaluate -> Loss: 0.1160, Accuracy (potentially includes padding): 0.9478\n","  Generating predictions...\n","  Total time steps: 152644, Non-padded steps: 22423\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.6444\n","    Precision: 0.6416\n","    Recall:    0.6444\n","    F1-score:  0.6404\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.6734    0.7082    0.6904     10083\n","           H     0.6301    0.6887    0.6581      7121\n","           E     0.5959    0.4608    0.5197      5219\n","\n","    accuracy                         0.6444     22423\n","   macro avg     0.6331    0.6192    0.6227     22423\n","weighted avg     0.6416    0.6444    0.6404     22423\n","\n","\n","############################################################\n","# Training Model: BiGRU_Protein_SS_Model\n","############################################################\n","Epoch 1/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 365ms/step - accuracy: 0.8921 - loss: 0.1996 - val_accuracy: 0.9218 - val_loss: 0.1727\n","Epoch 2/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 234ms/step - accuracy: 0.8908 - loss: 0.1630 - val_accuracy: 0.9250 - val_loss: 0.1669\n","Epoch 3/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 234ms/step - accuracy: 0.9248 - loss: 0.1653 - val_accuracy: 0.9260 - val_loss: 0.1642\n","Epoch 4/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 236ms/step - accuracy: 0.9265 - loss: 0.1622 - val_accuracy: 0.9261 - val_loss: 0.1625\n","Epoch 5/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 235ms/step - accuracy: 0.9295 - loss: 0.1556 - val_accuracy: 0.9277 - val_loss: 0.1606\n","Epoch 6/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 235ms/step - accuracy: 0.9262 - loss: 0.1634 - val_accuracy: 0.9282 - val_loss: 0.1595\n","Epoch 7/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 239ms/step - accuracy: 0.9295 - loss: 0.1557 - val_accuracy: 0.9289 - val_loss: 0.1588\n","Epoch 8/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 238ms/step - accuracy: 0.9301 - loss: 0.1545 - val_accuracy: 0.9292 - val_loss: 0.1579\n","Epoch 9/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 237ms/step - accuracy: 0.9288 - loss: 0.1579 - val_accuracy: 0.9292 - val_loss: 0.1572\n","Epoch 10/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 236ms/step - accuracy: 0.9306 - loss: 0.1545 - val_accuracy: 0.9308 - val_loss: 0.1566\n","Epoch 11/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 239ms/step - accuracy: 0.9310 - loss: 0.1550 - val_accuracy: 0.9285 - val_loss: 0.1604\n","Epoch 12/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 235ms/step - accuracy: 0.9328 - loss: 0.1506 - val_accuracy: 0.9310 - val_loss: 0.1549\n","Epoch 13/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 238ms/step - accuracy: 0.9312 - loss: 0.1539 - val_accuracy: 0.9304 - val_loss: 0.1553\n","Epoch 14/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 236ms/step - accuracy: 0.9345 - loss: 0.1476 - val_accuracy: 0.9326 - val_loss: 0.1536\n","Epoch 15/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 233ms/step - accuracy: 0.9354 - loss: 0.1461 - val_accuracy: 0.9337 - val_loss: 0.1508\n","Epoch 16/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 232ms/step - accuracy: 0.9352 - loss: 0.1472 - val_accuracy: 0.9342 - val_loss: 0.1497\n","Epoch 17/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 234ms/step - accuracy: 0.9352 - loss: 0.1476 - val_accuracy: 0.9349 - val_loss: 0.1492\n","Epoch 18/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 236ms/step - accuracy: 0.9400 - loss: 0.1368 - val_accuracy: 0.9355 - val_loss: 0.1475\n","Epoch 19/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 238ms/step - accuracy: 0.9391 - loss: 0.1401 - val_accuracy: 0.9331 - val_loss: 0.1518\n","Epoch 20/20\n","\u001b[1m117/117\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 239ms/step - accuracy: 0.9350 - loss: 0.1488 - val_accuracy: 0.9350 - val_loss: 0.1486\n","Restoring model weights from the end of the best epoch: 18.\n","\n","--- Finished Training BiGRU_Protein_SS_Model ---\n","\n","--- Evaluating on Training Set ---\n","  Keras Evaluate -> Loss: 0.1405, Accuracy (potentially includes padding): 0.9390\n","  Generating predictions...\n","  Total time steps: 1147292, Non-padded steps: 222287\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.6854\n","    Precision: 0.6865\n","    Recall:    0.6854\n","    F1-score:  0.6828\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.6627    0.7631    0.7093     94285\n","           H     0.7372    0.6901    0.7129     81251\n","           E     0.6465    0.5207    0.5768     46751\n","\n","    accuracy                         0.6854    222287\n","   macro avg     0.6821    0.6580    0.6663    222287\n","weighted avg     0.6865    0.6854    0.6828    222287\n","\n","\n","--- Evaluating on Validation Set ---\n","  Keras Evaluate -> Loss: 0.1475, Accuracy (potentially includes padding): 0.9355\n","  Generating predictions...\n","  Total time steps: 288054, Non-padded steps: 57068\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.6747\n","    Precision: 0.6745\n","    Recall:    0.6747\n","    F1-score:  0.6718\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.6600    0.7536    0.7037     24391\n","           H     0.7210    0.6805    0.7001     20567\n","           E     0.6249    0.5060    0.5592     12110\n","\n","    accuracy                         0.6747     57068\n","   macro avg     0.6686    0.6467    0.6543     57068\n","weighted avg     0.6745    0.6747    0.6718     57068\n","\n","\n","--- Evaluating on Test Set ---\n","  Keras Evaluate -> Loss: 0.1106, Accuracy (potentially includes padding): 0.9516\n","  Generating predictions...\n","  Total time steps: 152644, Non-padded steps: 22423\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.6708\n","    Precision: 0.6704\n","    Recall:    0.6708\n","    F1-score:  0.6675\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.6645    0.7632    0.7104     10083\n","           H     0.7231    0.6586    0.6894      7121\n","           E     0.6098    0.5091    0.5549      5219\n","\n","    accuracy                         0.6708     22423\n","   macro avg     0.6658    0.6436    0.6516     22423\n","weighted avg     0.6704    0.6708    0.6675     22423\n","\n","\n","======================================================================\n","Final Performance Summary (Including Bidirectional Models)\n","======================================================================\n","\n","--- SimpleRNN ---\n","  Training Set:\n","    Accuracy:  0.5596 (on non-padded steps)\n","    Precision: 0.5549\n","    Recall:    0.5596\n","    F1-score:  0.5538\n","    Loss:      0.1803\n","  Validation Set:\n","    Accuracy:  0.5630 (on non-padded steps)\n","    Precision: 0.5579\n","    Recall:    0.5630\n","    F1-score:  0.5573\n","    Loss:      0.1843\n","  Test Set:\n","    Accuracy:  0.5524 (on non-padded steps)\n","    Precision: 0.5463\n","    Recall:    0.5524\n","    F1-score:  0.5462\n","    Loss:      0.1385\n","----------------------------------------\n","\n","--- BiLSTM ---\n","  Training Set:\n","    Accuracy:  0.6681 (on non-padded steps)\n","    Precision: 0.6673\n","    Recall:    0.6681\n","    F1-score:  0.6635\n","    Loss:      0.1464\n","  Validation Set:\n","    Accuracy:  0.6577 (on non-padded steps)\n","    Precision: 0.6559\n","    Recall:    0.6577\n","    F1-score:  0.6521\n","    Loss:      0.1539\n","  Test Set:\n","    Accuracy:  0.6444 (on non-padded steps)\n","    Precision: 0.6416\n","    Recall:    0.6444\n","    F1-score:  0.6404\n","    Loss:      0.1160\n","----------------------------------------\n","\n","--- BiGRU ---\n","  Training Set:\n","    Accuracy:  0.6854 (on non-padded steps)\n","    Precision: 0.6865\n","    Recall:    0.6854\n","    F1-score:  0.6828\n","    Loss:      0.1405\n","  Validation Set:\n","    Accuracy:  0.6747 (on non-padded steps)\n","    Precision: 0.6745\n","    Recall:    0.6747\n","    F1-score:  0.6718\n","    Loss:      0.1475\n","  Test Set:\n","    Accuracy:  0.6708 (on non-padded steps)\n","    Precision: 0.6704\n","    Recall:    0.6708\n","    F1-score:  0.6675\n","    Loss:      0.1106\n","----------------------------------------\n","\n","======================================================================\n","Detailed Classification Reports (Including Bidirectional Models)\n","======================================================================\n","\n","--- SimpleRNN ---\n","  Training Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.5777    0.6624    0.6171     94285\n","           H     0.5621    0.5532    0.5576     81251\n","           E     0.4967    0.3634    0.4197     46751\n","\n","    accuracy                         0.5596    222287\n","   macro avg     0.5455    0.5263    0.5315    222287\n","weighted avg     0.5549    0.5596    0.5538    222287\n","\n","--------------------\n","  Validation Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.5863    0.6655    0.6234     24391\n","           H     0.5618    0.5577    0.5597     20567\n","           E     0.4938    0.3657    0.4202     12110\n","\n","    accuracy                         0.5630     57068\n","   macro avg     0.5473    0.5296    0.5345     57068\n","weighted avg     0.5579    0.5630    0.5573     57068\n","\n","--------------------\n","  Test Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.5897    0.6742    0.6292     10083\n","           H     0.5269    0.5121    0.5194      7121\n","           E     0.4887    0.3721    0.4225      5219\n","\n","    accuracy                         0.5524     22423\n","   macro avg     0.5351    0.5195    0.5237     22423\n","weighted avg     0.5463    0.5524    0.5462     22423\n","\n","--------------------\n","----------------------------------------\n","\n","--- BiLSTM ---\n","  Training Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.6744    0.7140    0.6936     94285\n","           H     0.6659    0.7315    0.6972     81251\n","           E     0.6551    0.4655    0.5443     46751\n","\n","    accuracy                         0.6681    222287\n","   macro avg     0.6652    0.6370    0.6450    222287\n","weighted avg     0.6673    0.6681    0.6635    222287\n","\n","--------------------\n","  Validation Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.6733    0.7087    0.6905     24391\n","           H     0.6502    0.7266    0.6863     20567\n","           E     0.6307    0.4379    0.5169     12110\n","\n","    accuracy                         0.6577     57068\n","   macro avg     0.6514    0.6244    0.6312     57068\n","weighted avg     0.6559    0.6577    0.6521     57068\n","\n","--------------------\n","  Test Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.6734    0.7082    0.6904     10083\n","           H     0.6301    0.6887    0.6581      7121\n","           E     0.5959    0.4608    0.5197      5219\n","\n","    accuracy                         0.6444     22423\n","   macro avg     0.6331    0.6192    0.6227     22423\n","weighted avg     0.6416    0.6444    0.6404     22423\n","\n","--------------------\n","----------------------------------------\n","\n","--- BiGRU ---\n","  Training Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.6627    0.7631    0.7093     94285\n","           H     0.7372    0.6901    0.7129     81251\n","           E     0.6465    0.5207    0.5768     46751\n","\n","    accuracy                         0.6854    222287\n","   macro avg     0.6821    0.6580    0.6663    222287\n","weighted avg     0.6865    0.6854    0.6828    222287\n","\n","--------------------\n","  Validation Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.6600    0.7536    0.7037     24391\n","           H     0.7210    0.6805    0.7001     20567\n","           E     0.6249    0.5060    0.5592     12110\n","\n","    accuracy                         0.6747     57068\n","   macro avg     0.6686    0.6467    0.6543     57068\n","weighted avg     0.6745    0.6747    0.6718     57068\n","\n","--------------------\n","  Test Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.6645    0.7632    0.7104     10083\n","           H     0.7231    0.6586    0.6894      7121\n","           E     0.6098    0.5091    0.5549      5219\n","\n","    accuracy                         0.6708     22423\n","   macro avg     0.6658    0.6436    0.6516     22423\n","weighted avg     0.6704    0.6708    0.6675     22423\n","\n","--------------------\n","----------------------------------------\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Input, LSTM, GRU, Dense, TimeDistributed, Dropout, Bidirectional\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n","import os\n","import copy # Needed for Bidirectional layer definition from config potentiallyb\n","\n","# --- Configuration (can reuse from Task 3 or redefine if needed) ---\n","EPOCHS = 20          # Maximum number of epochs\n","BATCH_SIZE = 8      # Samples per gradient update\n","PATIENCE = 5         # How many epochs to wait for improvement before stopping early\n","RNN_UNITS = 64       # RNN units (same as before for comparison)\n","DROPOUT_RATE = 0.3   # Dropout rate (same as before for comparison)\n","# MODEL_SAVE_DIR = \"saved_models\" # Defined in Task 3\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"Part II - Task 4: Train and Evaluate Bidirectional Models\")\n","print(\"=\"*60)\n","\n","# --- Ensure Data and Base Variables Exist ---\n","# --- Also reuse the evaluate_model_performance function ---\n","try:\n","    # Data from Part I\n","    _ = X_train, Y_train, X_val, Y_val, X_test, Y_test\n","    # Variables from Part I\n","    _ = max_len, NUM_AMINO_ACIDS, NUM_SECONDARY_STRUCTURES\n","    # Evaluation function from Task 3\n","    _ = evaluate_model_performance\n","    # Datasets dictionary from Task 3\n","    _ = datasets\n","    # Results dictionary from Task 3 (we'll add to this)\n","    _ = results\n","\n","    print(\"Successfully loaded data, variables, evaluation function, and datasets dict from previous parts.\")\n","    print(f\"Input shape: {(max_len, NUM_AMINO_ACIDS)}, Output classes: {NUM_SECONDARY_STRUCTURES}\")\n","\n","except NameError as e:\n","    print(\"\\n--- ERROR ---\")\n","    print(f\"Variable, Function or Dictionary not found: {e}\")\n","    print(\"Please ensure Part I (data prep), Part II Task 1 (model def), and Task 3 (uni-training/eval func)\")\n","    print(\"have been executed successfully in the same session before running this task.\")\n","    print(\"Cannot proceed with training.\")\n","    print(\"-------------\")\n","    exit() # Stop if setup is incomplete\n","\n","\n","# --- Helper function to build Bidirectional models ---\n","# (Similar to Task 1, but incorporates Bidirectional wrapper)\n","def build_and_report_bidirectional_model(model_type, units, dropout_rate, input_shape, output_classes, merge_mode='concat'):\n","    \"\"\"Builds, compiles, and prints the summary for a Bidirectional RNN model.\"\"\"\n","\n","    if model_type == 'BiLSTM':\n","        # Define the base LSTM layer\n","        base_rnn_layer = LSTM(units, return_sequences=True) # Must return sequences!\n","        model_name = 'BiLSTM_Protein_SS_Model'\n","    elif model_type == 'BiGRU':\n","        # Define the base GRU layer\n","        base_rnn_layer = GRU(units, return_sequences=True) # Must return sequences!\n","        model_name = 'BiGRU_Protein_SS_Model'\n","    else:\n","        raise ValueError(\"Unsupported model_type for bidirectional. Choose 'BiLSTM' or 'BiGRU'.\")\n","\n","    print(\"\\n\" + \"=\"*60)\n","    print(f\"Building Model: {model_name}\")\n","    print(\"=\"*60)\n","\n","    model = Sequential(name=model_name)\n","    # Define Input Layer explicitly\n","    model.add(Input(shape=input_shape, name='Input_Sequence'))\n","\n","    # --- Bidirectional RNN Layer ---\n","    # Wrap the base RNN layer with Bidirectional\n","    # merge_mode='concat' (default) concatenates forward and backward outputs,\n","    # doubling the feature dimension passed to the next layer.\n","    model.add(Bidirectional(base_rnn_layer, merge_mode=merge_mode))\n","\n","    # Optional Dropout layer for regularization\n","    if dropout_rate > 0:\n","        model.add(Dropout(dropout_rate, name='BiRNN_Dropout'))\n","\n","    # --- Output Layer (Same as before) ---\n","    # TimeDistributed applies Dense layer to each time step\n","    model.add(TimeDistributed(Dense(output_classes, activation='softmax'), name='Output_Probabilities'))\n","\n","    # --- Compile the Model (Same as before) ---\n","    model.compile(optimizer='adam',\n","                  loss='categorical_crossentropy',\n","                  metrics=['accuracy'])\n","\n","    # --- Report Summary ---\n","    print(f\"\\n--- Model Summary for {model_name} ---\")\n","    model.summary()\n","    total_params = model.count_params()\n","    print(f\"\\nTotal number of parameters to optimize: {total_params:,}\")\n","    print(\"=\"*60)\n","\n","    return model\n","\n","# --- Define and Build Bidirectional Models ---\n","input_shape = (max_len, NUM_AMINO_ACIDS)\n","output_classes = NUM_SECONDARY_STRUCTURES\n","\n","model_bilstm = build_and_report_bidirectional_model(\n","    model_type='BiLSTM',\n","    units=RNN_UNITS,\n","    dropout_rate=DROPOUT_RATE,\n","    input_shape=input_shape,\n","    output_classes=output_classes\n",")\n","\n","model_bigru = build_and_report_bidirectional_model(\n","    model_type='BiGRU',\n","    units=RNN_UNITS,\n","    dropout_rate=DROPOUT_RATE,\n","    input_shape=input_shape,\n","    output_classes=output_classes\n",")\n","\n","# Dictionary for the new models to train\n","models_to_train_bi = {\n","    \"BiLSTM\": model_bilstm,\n","    \"BiGRU\": model_bigru\n","}\n","\n","# --- Train and Evaluate Bidirectional Models ---\n","# (Using the same loop structure and evaluation function as Task 3)\n","for model_name, model in models_to_train_bi.items():\n","    print(\"\\n\" + \"#\"*60)\n","    print(f\"# Training Model: {model.name}\")\n","    print(\"#\"*60)\n","\n","    # Define Callbacks (same as Task 3)\n","    early_stopping = EarlyStopping(\n","        monitor='val_loss',\n","        patience=PATIENCE,\n","        verbose=1,\n","        restore_best_weights=True\n","    )\n","    callbacks_list = [early_stopping]\n","\n","    # Train the Model\n","    history = model.fit(\n","        X_train, Y_train,\n","        epochs=EPOCHS,\n","        batch_size=BATCH_SIZE,\n","        validation_data=(X_val, Y_val),\n","        callbacks=callbacks_list,\n","        verbose=1\n","    )\n","\n","    print(f\"\\n--- Finished Training {model.name} ---\")\n","\n","    # Evaluate the Model using the function from Task 3\n","    model_results_bi = {}\n","    for dataset_name, (x_data, y_data) in datasets.items():\n","         # Ensure test set is only evaluated if it exists and is non-empty\n","         if dataset_name == \"Test\" and (x_data is None or x_data.shape[0] == 0):\n","             print(\"\\nSkipping evaluation on empty Test set.\")\n","             model_results_bi[dataset_name] = {\"loss\": None, \"accuracy\": None, \"precision\": None, \"recall\": None, \"f1_score\": None, \"report\": \"Test set empty\"}\n","             continue\n","         if y_data is None or y_data.shape[0] == 0:\n","             print(f\"\\nSkipping evaluation on {dataset_name} set due to empty Y data.\")\n","             model_results_bi[dataset_name] = {\"loss\": None, \"accuracy\": None, \"precision\": None, \"recall\": None, \"f1_score\": None, \"report\": f\"{dataset_name} set Y empty\"}\n","             continue\n","\n","         model_results_bi[dataset_name] = evaluate_model_performance(model, x_data, y_data, dataset_name)\n","\n","    # Add the results for this bidirectional model to the main results dictionary\n","    results[model_name] = model_results_bi\n","\n","    import gc\n","    tf.keras.backend.clear_session()\n","    gc.collect()\n","\n","\n","# --- Requirement: Report Final Metrics (Now includes Bidirectional models) ---\n","print(\"\\n\" + \"=\"*70)\n","print(\"Final Performance Summary (Including Bidirectional Models)\")\n","print(\"=\"*70)\n","\n","# Iterate through the updated results dictionary which now contains all models\n","for model_name, model_results in results.items():\n","    print(f\"\\n--- {model_name} ---\")\n","    for dataset_name, metrics in model_results.items():\n","        if 'accuracy' in metrics and metrics['accuracy'] is not None:\n","            print(f\"  {dataset_name} Set:\")\n","            print(f\"    Accuracy:  {metrics['accuracy']:.4f} (on non-padded steps)\")\n","            print(f\"    Precision: {metrics['precision']:.4f}\")\n","            print(f\"    Recall:    {metrics['recall']:.4f}\")\n","            print(f\"    F1-score:  {metrics['f1_score']:.4f}\")\n","            print(f\"    Loss:      {metrics['loss']:.4f}\")\n","        else:\n","            print(f\"  {dataset_name} Set: Not Evaluated ({metrics.get('report', 'Reason unknown')})\")\n","    print(\"-\" * 40)\n","\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"Detailed Classification Reports (Including Bidirectional Models)\")\n","print(\"=\"*70)\n","# Iterate through the updated results dictionary\n","for model_name, model_results in results.items():\n","    print(f\"\\n--- {model_name} ---\")\n","    for dataset_name, metrics in model_results.items():\n","        if 'report' in metrics and metrics.get('accuracy') is not None: # Check if report exists and evaluation happened\n","             print(f\"  {dataset_name} Set Report:\")\n","             print(metrics['report'])\n","             print(\"-\" * 20)\n","        elif 'report' in metrics:\n","             print(f\"  {dataset_name} Set: Not Evaluated ({metrics['report']})\")\n","             print(\"-\" * 20)\n","    print(\"-\" * 40)"]},{"cell_type":"markdown","metadata":{"id":"Z8k1caqJgs-S"},"source":["###TASK - 5"]},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv1D, Dropout, Dense, TimeDistributed, BatchNormalization\n","from tensorflow.keras.callbacks import EarlyStopping\n","from sklearn.metrics import classification_report, accuracy_score, precision_recall_fscore_support\n","import os\n","\n","# --- Configuration ---\n","EPOCHS = 18\n","BATCH_SIZE = 16\n","PATIENCE = 5\n","MODEL_SAVE_DIR = \"saved_models\"\n","\n","print(\"\\n\" + \"=\"*60)\n","print(\"Part II - Task 3: Train and Evaluate Models on Real Data\")\n","print(\"=\"*60)\n","\n","# --- Ensure Data and Models Exist ---\n","try:\n","    _ = X_train, Y_train, X_val, Y_val, X_test, Y_test\n","    _ = model_simple_rnn, model_lstm, model_gru\n","    _ = max_len, NUM_AMINO_ACIDS, NUM_SECONDARY_STRUCTURES\n","\n","    print(\"Successfully loaded data and models from previous parts.\")\n","    print(f\"Training data shape: X={X_train.shape}, Y={Y_train.shape}\")\n","    print(f\"Validation data shape: X={X_val.shape}, Y={Y_val.shape}\")\n","    print(f\"Test data shape: X={X_test.shape}, Y={Y_test.shape}\")\n","\n","    models_to_train = {}\n","    datasets = {\n","        \"Training\": (X_train, Y_train),\n","        \"Validation\": (X_val, Y_val),\n","        \"Test\": (X_test, Y_test)\n","    }\n","    results = {}\n","\n","except NameError as e:\n","    print(\"\\n--- ERROR ---\")\n","    print(f\"Variable or Model not found: {e}\")\n","    print(\"Please ensure Part I (data prep) and Part II Task 1 (model definition)\")\n","    print(\"have been executed successfully in the same session before running this task.\")\n","    exit()\n","\n","# --- Define CNN Model ---\n","def build_cnn_model(input_shape, num_classes):\n","    inputs = Input(shape=input_shape)\n","    x = Conv1D(filters=128, kernel_size=7, padding=\"same\", activation=\"relu\")(inputs)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.3)(x)\n","    x = Conv1D(filters=64, kernel_size=5, padding=\"same\", activation=\"relu\")(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.3)(x)\n","    x = Conv1D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\")(x)\n","    x = TimeDistributed(Dense(num_classes, activation=\"softmax\"))(x)\n","    model = Model(inputs, x, name=\"cnn_model\")\n","    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","    return model\n","\n","# --- Add CNN to Models ---\n","model_cnn = build_cnn_model((max_len, NUM_AMINO_ACIDS), NUM_SECONDARY_STRUCTURES)\n","models_to_train[\"CNN\"] = model_cnn\n","\n","# --- Helper Function for Masked Evaluation ---\n","def evaluate_model_performance(model, x_data, y_data, dataset_name):\n","    print(f\"\\n--- Evaluating on {dataset_name} Set ---\")\n","    loss, accuracy = model.evaluate(x_data, y_data, verbose=0, batch_size=BATCH_SIZE)\n","    print(f\"  Keras Evaluate -> Loss: {loss:.4f}, Accuracy (potentially includes padding): {accuracy:.4f}\")\n","\n","    print(\"  Generating predictions...\")\n","    y_pred_prob = model.predict(x_data, batch_size=BATCH_SIZE, verbose=0)\n","    y_pred_indices = np.argmax(y_pred_prob, axis=-1)\n","    y_true_indices = np.argmax(y_data, axis=-1)\n","    mask = np.sum(x_data, axis=-1) > 1e-6\n","    y_pred_flat_masked = y_pred_indices[mask]\n","    y_true_flat_masked = y_true_indices[mask]\n","\n","    print(f\"  Total time steps: {mask.size}, Non-padded steps: {np.sum(mask)}\")\n","    if np.sum(mask) == 0:\n","        print(\"  Warning: No non-padded steps found based on input mask. Cannot calculate detailed metrics.\")\n","        return {\n","            \"loss\": loss,\n","            \"accuracy_keras\": accuracy,\n","            \"accuracy\": 0.0 if accuracy is not None else None,\n","            \"precision\": 0.0,\n","            \"recall\": 0.0,\n","            \"f1_score\": 0.0,\n","            \"report\": \"No non-padded steps\"}\n","\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        y_true_flat_masked, y_pred_flat_masked, average='weighted', zero_division=0)\n","    accuracy_masked = accuracy_score(y_true_flat_masked, y_pred_flat_masked)\n","\n","    print(f\"  Metrics (on non-padded steps):\")\n","    print(f\"    Accuracy:  {accuracy_masked:.4f}\")\n","    print(f\"    Precision: {precision:.4f}\")\n","    print(f\"    Recall:    {recall:.4f}\")\n","    print(f\"    F1-score:  {f1:.4f}\")\n","\n","    try:\n","        target_names_list = list(SECONDARY_STRUCTURES) if 'SECONDARY_STRUCTURES' in globals() else [f'Class_{i}' for i in range(NUM_SECONDARY_STRUCTURES)]\n","        report = classification_report(y_true_flat_masked, y_pred_flat_masked, target_names=target_names_list, digits=4, zero_division=0)\n","        print(\"  Classification Report (on non-padded steps):\\n\", report)\n","    except Exception as report_err:\n","        print(f\"  Could not generate classification report: {report_err}\")\n","        report = \"Error generating report\"\n","\n","    return {\n","        \"loss\": loss,\n","        \"accuracy_keras\": accuracy,\n","        \"accuracy\": accuracy_masked,\n","        \"precision\": precision,\n","        \"recall\": recall,\n","        \"f1_score\": f1,\n","        \"report\": report\n","    }\n","\n","# --- Create directory for saving models (optional) ---\n","if not os.path.exists(MODEL_SAVE_DIR):\n","    try:\n","        os.makedirs(MODEL_SAVE_DIR)\n","        print(f\"Created directory for saving models: {MODEL_SAVE_DIR}\")\n","    except OSError as e:\n","        print(f\"Error creating directory {MODEL_SAVE_DIR}: {e}\")\n","\n","# --- Train and Evaluate Each Model ---\n","for model_name, model in models_to_train.items():\n","    print(\"\\n\" + \"#\"*60)\n","    print(f\"# Training Model: {model.name}\")\n","    print(\"#\"*60)\n","\n","    early_stopping = EarlyStopping(\n","        monitor='val_loss',\n","        patience=PATIENCE,\n","        verbose=1,\n","        restore_best_weights=True\n","    )\n","    callbacks_list = [early_stopping]\n","\n","    history = model.fit(\n","        X_train, Y_train,\n","        epochs=EPOCHS,\n","        batch_size=BATCH_SIZE,\n","        validation_data=(X_val, Y_val),\n","        callbacks=callbacks_list,\n","        verbose=1\n","    )\n","\n","    print(f\"\\n--- Finished Training {model.name} ---\")\n","\n","    model_results = {}\n","    for dataset_name, (x_data, y_data) in datasets.items():\n","        if dataset_name == \"Test\" and (x_data is None or x_data.shape[0] == 0):\n","            print(\"\\nSkipping evaluation on empty Test set.\")\n","            model_results[dataset_name] = {\"loss\": None, \"accuracy\": None, \"precision\": None, \"recall\": None, \"f1_score\": None, \"report\": \"Test set empty\"}\n","            continue\n","        if y_data is None or y_data.shape[0] == 0:\n","            print(f\"\\nSkipping evaluation on {dataset_name} set due to empty Y data.\")\n","            model_results[dataset_name] = {\"loss\": None, \"accuracy\": None, \"precision\": None, \"recall\": None, \"f1_score\": None, \"report\": f\"{dataset_name} set Y empty\"}\n","            continue\n","        model_results[dataset_name] = evaluate_model_performance(model, x_data, y_data, dataset_name)\n","\n","    results[model_name] = model_results\n","\n","# --- Report Final Metrics ---\n","print(\"\\n\" + \"=\"*70)\n","print(\"Final Performance Summary\")\n","print(\"=\"*70)\n","\n","for model_name, model_results in results.items():\n","    print(f\"\\n--- {model_name} ---\")\n","    for dataset_name, metrics in model_results.items():\n","        if 'accuracy' in metrics and metrics['accuracy'] is not None:\n","            print(f\"  {dataset_name} Set:\")\n","            print(f\"    Accuracy:  {metrics['accuracy']:.4f} (on non-padded steps)\")\n","            print(f\"    Precision: {metrics['precision']:.4f}\")\n","            print(f\"    Recall:    {metrics['recall']:.4f}\")\n","            print(f\"    F1-score:  {metrics['f1_score']:.4f}\")\n","            print(f\"    Loss:      {metrics['loss']:.4f}\")\n","        else:\n","            print(f\"  {dataset_name} Set: Not Evaluated ({metrics.get('report', 'Reason unknown')})\")\n","    print(\"-\" * 40)\n","\n","print(\"\\n\" + \"=\"*70)\n","print(\"Detailed Classification Reports (on non-padded steps)\")\n","print(\"=\"*70)\n","for model_name, model_results in results.items():\n","    print(f\"\\n--- {model_name} ---\")\n","    for dataset_name, metrics in model_results.items():\n","        if 'report' in metrics and metrics['accuracy'] is not None:\n","            print(f\"  {dataset_name} Set Report:\")\n","            print(metrics['report'])\n","            print(\"-\" * 20)\n","        elif 'report' in metrics:\n","            print(f\"  {dataset_name} Set: Not Evaluated ({metrics['report']})\")\n","            print(\"-\" * 20)\n","    print(\"-\" * 40)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Vc4g-Qq0jCF","executionInfo":{"status":"ok","timestamp":1743717625577,"user_tz":300,"elapsed":1114141,"user":{"displayName":"Matthew Mueller","userId":"09372831935304640262"}},"outputId":"a723c94c-3d3f-4782-a1bb-29d6d6c5f9ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","============================================================\n","Part II - Task 3: Train and Evaluate Models on Real Data\n","============================================================\n","Successfully loaded data and models from previous parts.\n","Training data shape: X=(932, 1231, 20), Y=(932, 1231, 3)\n","Validation data shape: X=(234, 1231, 20), Y=(234, 1231, 3)\n","Test data shape: X=(124, 1231, 20), Y=(124, 1231, 3)\n","\n","############################################################\n","# Training Model: cnn_model\n","############################################################\n","Epoch 1/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m589s\u001b[0m 6s/step - accuracy: 0.0860 - loss: 0.2841 - val_accuracy: 0.0827 - val_loss: 0.2104\n","Epoch 2/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.1100 - loss: 0.1794 - val_accuracy: 0.0822 - val_loss: 0.2104\n","Epoch 3/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.1161 - loss: 0.1707 - val_accuracy: 0.0940 - val_loss: 0.1998\n","Epoch 4/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.1165 - loss: 0.1634 - val_accuracy: 0.1111 - val_loss: 0.1925\n","Epoch 5/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.1259 - loss: 0.1678 - val_accuracy: 0.1178 - val_loss: 0.1891\n","Epoch 6/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.1238 - loss: 0.1600 - val_accuracy: 0.1155 - val_loss: 0.1852\n","Epoch 7/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.1289 - loss: 0.1558 - val_accuracy: 0.1190 - val_loss: 0.1806\n","Epoch 8/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.1260 - loss: 0.1521 - val_accuracy: 0.1254 - val_loss: 0.1730\n","Epoch 9/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.1277 - loss: 0.1498 - val_accuracy: 0.1276 - val_loss: 0.1700\n","Epoch 10/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.1292 - loss: 0.1517 - val_accuracy: 0.1321 - val_loss: 0.1609\n","Epoch 11/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.1263 - loss: 0.1439 - val_accuracy: 0.1343 - val_loss: 0.1562\n","Epoch 12/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.1302 - loss: 0.1460 - val_accuracy: 0.1340 - val_loss: 0.1535\n","Epoch 13/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.1293 - loss: 0.1419 - val_accuracy: 0.1345 - val_loss: 0.1520\n","Epoch 14/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.1333 - loss: 0.1467 - val_accuracy: 0.1346 - val_loss: 0.1512\n","Epoch 15/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.1300 - loss: 0.1398 - val_accuracy: 0.1349 - val_loss: 0.1516\n","Epoch 16/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.1355 - loss: 0.1462 - val_accuracy: 0.1350 - val_loss: 0.1508\n","Epoch 17/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.1323 - loss: 0.1407 - val_accuracy: 0.1351 - val_loss: 0.1505\n","Epoch 18/18\n","\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.1355 - loss: 0.1426 - val_accuracy: 0.1353 - val_loss: 0.1500\n","Restoring model weights from the end of the best epoch: 18.\n","\n","--- Finished Training cnn_model ---\n","\n","--- Evaluating on Training Set ---\n","  Keras Evaluate -> Loss: 0.1340, Accuracy (potentially includes padding): 0.1393\n","  Generating predictions...\n","  Total time steps: 1147292, Non-padded steps: 222287\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.7032\n","    Precision: 0.7034\n","    Recall:    0.7032\n","    F1-score:  0.7004\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.6830    0.7777    0.7272     94285\n","           H     0.7530    0.7174    0.7348     81251\n","           E     0.6585    0.5286    0.5864     46751\n","\n","    accuracy                         0.7032    222287\n","   macro avg     0.6982    0.6745    0.6828    222287\n","weighted avg     0.7034    0.7032    0.7004    222287\n","\n","\n","--- Evaluating on Validation Set ---\n","  Keras Evaluate -> Loss: 0.1500, Accuracy (potentially includes padding): 0.1353\n","  Generating predictions...\n","  Total time steps: 288054, Non-padded steps: 57068\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.6678\n","    Precision: 0.6658\n","    Recall:    0.6678\n","    F1-score:  0.6644\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.6639    0.7493    0.7040     24391\n","           H     0.7087    0.6794    0.6937     20567\n","           E     0.5969    0.4841    0.5346     12110\n","\n","    accuracy                         0.6678     57068\n","   macro avg     0.6565    0.6376    0.6441     57068\n","weighted avg     0.6658    0.6678    0.6644     57068\n","\n","\n","--- Evaluating on Test Set ---\n","  Keras Evaluate -> Loss: 0.1131, Accuracy (potentially includes padding): 0.1001\n","  Generating predictions...\n","  Total time steps: 152644, Non-padded steps: 22423\n","  Metrics (on non-padded steps):\n","    Accuracy:  0.6614\n","    Precision: 0.6585\n","    Recall:    0.6614\n","    F1-score:  0.6565\n","  Classification Report (on non-padded steps):\n","               precision    recall  f1-score   support\n","\n","           C     0.6668    0.7530    0.7073     10083\n","           H     0.6801    0.6728    0.6764      7121\n","           E     0.6128    0.4689    0.5313      5219\n","\n","    accuracy                         0.6614     22423\n","   macro avg     0.6532    0.6315    0.6383     22423\n","weighted avg     0.6585    0.6614    0.6565     22423\n","\n","\n","======================================================================\n","Final Performance Summary\n","======================================================================\n","\n","--- CNN ---\n","  Training Set:\n","    Accuracy:  0.7032 (on non-padded steps)\n","    Precision: 0.7034\n","    Recall:    0.7032\n","    F1-score:  0.7004\n","    Loss:      0.1340\n","  Validation Set:\n","    Accuracy:  0.6678 (on non-padded steps)\n","    Precision: 0.6658\n","    Recall:    0.6678\n","    F1-score:  0.6644\n","    Loss:      0.1500\n","  Test Set:\n","    Accuracy:  0.6614 (on non-padded steps)\n","    Precision: 0.6585\n","    Recall:    0.6614\n","    F1-score:  0.6565\n","    Loss:      0.1131\n","----------------------------------------\n","\n","======================================================================\n","Detailed Classification Reports (on non-padded steps)\n","======================================================================\n","\n","--- CNN ---\n","  Training Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.6830    0.7777    0.7272     94285\n","           H     0.7530    0.7174    0.7348     81251\n","           E     0.6585    0.5286    0.5864     46751\n","\n","    accuracy                         0.7032    222287\n","   macro avg     0.6982    0.6745    0.6828    222287\n","weighted avg     0.7034    0.7032    0.7004    222287\n","\n","--------------------\n","  Validation Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.6639    0.7493    0.7040     24391\n","           H     0.7087    0.6794    0.6937     20567\n","           E     0.5969    0.4841    0.5346     12110\n","\n","    accuracy                         0.6678     57068\n","   macro avg     0.6565    0.6376    0.6441     57068\n","weighted avg     0.6658    0.6678    0.6644     57068\n","\n","--------------------\n","  Test Set Report:\n","              precision    recall  f1-score   support\n","\n","           C     0.6668    0.7530    0.7073     10083\n","           H     0.6801    0.6728    0.6764      7121\n","           E     0.6128    0.4689    0.5313      5219\n","\n","    accuracy                         0.6614     22423\n","   macro avg     0.6532    0.6315    0.6383     22423\n","weighted avg     0.6585    0.6614    0.6565     22423\n","\n","--------------------\n","----------------------------------------\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}